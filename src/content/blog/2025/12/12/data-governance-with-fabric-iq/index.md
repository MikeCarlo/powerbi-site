---
title: "Data Governance with Fabric IQ – Ep. 484"
date: "2025-12-12"
authors:
  - "Mike Carlo"
  - "Tommy Puglia"
categories:
  - "Podcast"
  - "Power BI"
tags:
  - "Explicit Measures"
  - "Podcast"
  - "Fabric IQ"
  - "Data Governance"
  - "Ontology"
  - "Service Principal"
  - "Workspace Identity"
excerpt: "Mike and Tommy explore what data governance looks like in the Fabric IQ era, unpacking how ontology changes the governance conversation from policing data to defining business meaning. Plus, notebooks in pipelines now support service principals and workspace identity."
featuredImage: "./assets/featured.png"
---

Fresh off the Ignite announcements, Mike and Tommy dig into what data governance looks like with Fabric IQ in the picture. The ontology item doesn't just add metadata—it fundamentally shifts the governance conversation from "who can access what" to "what does this data actually mean?" They also celebrate a long-awaited feature: notebooks in pipelines now support service principals and workspace identity, eliminating the credential-tied-to-a-person problem.

<iframe 
  width="100%" 
  height="415" 
  src="https://www.youtube.com/embed/J2FY5M26Dvw" 
  title="Data Governance with Fabric IQ – Ep. 484"
  frameborder="0" 
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
  allowfullscreen
></iframe>

## News & Announcements

- [Run Notebooks in Pipelines with Service Principal or Workspace Identity](https://blog.fabric.microsoft.com/en-us/blog/run-notebooks-in-pipelines-with-service-principal-or-workspace-identity/) — Fabric notebooks in pipelines can now run under service principals or workspace identity instead of individual user credentials. Mike highlights this as a critical enterprise feature—when Tommy wins the lottery and leaves, the pipelines won't break because they were built under Tommy's credentials. Workspace identity is becoming the standard for production deployments.

- [Introducing Fabric IQ: The Semantic Foundation for Enterprise AI](https://blog.fabric.microsoft.com/blog/introducing-fabric-iq-the-semantic-foundation-for-enterprise-ai?ft=All&WT.mc_id=DP-MVP-5002621) — The main topic source. Mike and Tommy continue unpacking the Fabric IQ announcement from Ignite, this time through a data governance lens.

## Main Discussion: Data Governance in the Fabric IQ Era

### The Governance Shift

Traditional data governance focuses on access control, lineage, and compliance—who can see what, where did it come from, and are we following the rules. Fabric IQ's ontology introduces a new dimension: **semantic governance**—what does this data actually mean, and does everyone agree?

Mike argues this is the harder problem. Organizations can implement row-level security and data classification relatively easily. Getting marketing, sales, and finance to agree on what "customer" means? That's governance at a whole new level.

### Service Principals and Workspace Identity

Before diving into ontology, both spend significant time on the workspace identity feature. Key points:

- **The person problem** — When items are built under individual credentials, employee turnover breaks everything. Pipelines, connections, refresh schedules—all tied to someone who may leave
- **Workspace identity as the solution** — Build under the workspace identity so items belong to the workspace, not a person
- **Service principal for automation** — Notebooks in pipelines now support service principals, enabling proper CI/CD and automated workflows
- **Mind shift required** — Developers need to stop building under their own credentials by default

### Ontology as Governance Infrastructure

The ontology item in Fabric IQ gives governance teams something they've never had: a formal, machine-readable layer that defines business concepts. This means:

- **Definitions become enforceable** — Not just a glossary document that nobody reads, but actual metadata that AI and tools consume
- **Relationships are explicit** — How entities connect to each other is defined, not implied
- **AI can reason over governance** — Copilot and agents can check whether a query or report aligns with defined business concepts

### The Cultural Challenge

Tommy emphasizes that governance success depends on culture more than technology. Organizations that already struggle with data quality conversations will find ontology amplifies those struggles. The technology is ready—the question is whether organizations are mature enough to have the conversations ontology requires.

### Practical Steps

- **Start with what you govern today** — Extend existing governance frameworks rather than building new ones
- **Use workspace identity everywhere** — Make it the default for all production items
- **Pilot ontology in one domain** — Pick a well-understood business area and define its entities first
- **Connect governance to value** — Frame it as "AI readiness" rather than "more rules"

## Looking Forward

Mike and Tommy see data governance evolving from a compliance function to a strategic enabler. With Fabric IQ, the organizations that invest in clear business definitions and semantic alignment will be the ones where AI delivers real value. Those that skip governance will have AI that hallucinates on poorly defined data—which is arguably worse than no AI at all.

## Episode Transcript

Full verbatim transcript — click any timestamp to jump to that moment:

[0:00](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=0s) Morning everyone and welcome back to the explicit measures podcast with Tommy and Mike. Hello, Tommy. How are you doing? Hello, Mike. Good to see your face.

[0:35](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=35s) It's good to be back again. We are just clipping along, moving into our Thursday episode. , I feel like the end of this year, , Tommy, how we we typically go to the end of the year and it's like a lackluster, like there's not a lot of features being made. We're going into the holidays. It I don't feel like I'm getting that feeling. I still feel like I'm extremely overwhelmed with all the announcements at Ignite and trying to get my head around all the new features that were just landed and released with either within Fabric or this ontology thing. There's a lot of new things

[1:08](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=68s) Coming out the door. A ton of things. , do you feel the same way? Fabric IQ is again what at least what they're putting towards what I've been telling my wife. I'm like, well, they may or may not be completely changing my career again or like where I'm located because she's like, is this just a marketing push by Microsoft just a different words? I'm like, I don't think so. So, like just if they said the ontology by itself, that would be huge. But we're seeing a ton of

[1:40](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=100s) Stuff. I actually have some great news articles on what we can do with drill through and excel with direct link data what we're able to do with just some amazing things also the transition from all the legacy things Microsoft just came out with another article about from SSIS to fabric so we're seeing all these big things it's a nice way to end the year I will agree with that as well let's go through our main topic today our our main topic is going going to just be unpacking what potentially does

[2:13](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=133s) Data governance look like in lie of fabric IQ. Maybe Tommy and I are going to react to this a little bit. We've been talking a little bit about this so far. I think there's going to be some interesting topics around, , how do we unpack this new world that we're potentially stepping into. So that will be one that will be there as well. with that, let's go into some news items. Tommy, I have a news item here that I think is going to be very impactful or influential here in general with how you build things. , I'm very excited. I use a lot of notebooks. I'm a big fan of Python. I'm a big fan of Spark. Using the notebook experience. I

[2:46](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=166s) Even now have been using more of the TSQL experience. Do you use the TSQL notebooks, Tommy? , on and off, but I I really just stayed as close as I can to Python and Spark, but okay. I know for a lot of developers, it's pretty huge. Let me just say it this way. I like using the SQL Analytics Endpoint or the data warehouse experience, right? There's there's tabs, but it feels very traditional SQL to me. It doesn't really feel very modern. So, I like this notebook experience because a lot of times when I'm building SQL statements,

[3:18](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=198s) I'm building like a smaller statement. I'm exploring a single table. I I need to build another table. And so, a lot of times I'm comparing the output from multiple SQL queries like side by side. And to me, that feels much more fluid or natural inside the concept of a notebook. I can have multiple steps side by side in the notebooks. Well, the reason I love notebooks here and and because I'm I'm I'm gushing about notebooks here a little bit. I also want to point out here, you now can run notebooks in pipelines in a pipeline now using the service principle or the

[3:50](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=230s) Workspace identity. Tommy, this has been a big pain point of mine in general with the fabric ecosystem is Tommy, you go in, you build a pipeline, you build a semantic model, you link some things together. the credentials of you, Tommy, are attached to all the things that you're building. And let's say, Tommy, you win the lottery and you go on to better things or you decide to move out of the company. Well, now that you have all these like items that have been made by Tommy, if you get removed from the organization or you move on or

[4:24](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=264s) Whatever, your stuff is all broken. Eventually, those credentials will time out. People have to take over them. It's a complex painful thing and I think there's a mind shift happening here a little bit is instead of building all these items under your name you should be building them under the service principle and I really like this workspace identity. I think the workspace identity is pretty cool and I'm very excited to see the workspace identity get added to many more places inside fabric. What are your thoughts Tommy? Yeah actually I wanted to ask you more

[4:56](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=296s) About that. What are some of the most like impactful ways you're seeing the workspace identity be identity really just make a difference for not just you but obviously for your team? I think it's when we're able to use the workspace identity to connect to data sources, right? So sometimes you have a data source like a SQL server there's like a username and password that you're using to go connect to that. In other situations you can use a service principle directly to reach out to other items. So the more that I can use the workspace identity to create and manage connections between things, right,

[5:31](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=331s) That's where I'm finding value. So the like if I can get the semantic model to use the workspace identity to refresh things, if I can get this the semantic model to reach into the lakehouse using the workspace identity, these things make a lot more sense to me because then the connection is centrally managed. And to be honest, how I think about a workspace is the workspace is the place where everyone can work and build things together. I don't need individual user credentials tied to the data flow process. , another one that's interesting here, Tommy, is you

[6:02](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=362s) Know, when you go from dev to test to production, like different environments, well, you actually do want each workspace to have its own identity or way to access the different datas on the other side of things. And so that's where again I think the workspace identity makes a lot of sense here as well. Dude, and I think we're seeing a lot of that too with the being able to access the data on behalf of not just what you be doing before with the APIs, but with MCPs, with the automation, with the engetic side or the the agent side of

[6:35](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=395s) This too, just being able to do that on the behalf. , yeah. No, I I love that. That's that's a banger to start off with, too. And how much too with notebooks are you because when I think of APIs in PowerBI, I still think of XML la like that's really the most general. If not that, then I'm doing admin. But this really just brings us to the I think that pure development role of being able to access the service, being able to not just either run and get my

[7:09](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=429s) Audit data or deal with my semantic model, but you we're doing a ton of things now that are this is nothing but developer. It's it's a definitely a lot more developer, but I think it's a better practice here. Again, I just don't really love the fact that we have to tie everything back to a user credential all the time. It just makes sense. If I'm in a workspace and I have a pipeline and I have a semantic model and I have a notebook, right? Those things should be able to talk to each other without having to use a user. They should just work inside the context of the workspace. So, I'm going to put some

[7:41](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=461s) Documentation here in the chat window. The first one I'm putting here is just in general, what is the workspace identity? The example Microsoft gives here is is if you have a a Azure data lakeink gen 2. So this is something that's an Azure resource and the Azure resource needs to get grant access to something to read those those lakehouse tables. So sometimes you're putting data in a lakehouse, sometimes you're putting in an ADLS gen 2. The workspace doesn't have to use Tommy's credentials to go access the Azure data lakeink gen 2 storage. Instead you would create the workspace

[8:14](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=494s) Identity and use that to go back to reach into the the Azure data lake gen 2 and get the information. So so the credentials can be given directly from the workspace. It's almost like adding a service principle to the workspace and then using that this is the same pattern I see happening with people and user accounts. I don't like this idea but people do it. They'll build a PowerBI service account. So it be like PowerBI companyame.com and what they do is they use that identity that way to everything. Yeah.

[8:45](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=525s) Log into everything like that. That is the user ID. So they're basically making a fake user and I don't like that because now you have to share passwords. Now you're sharing usernames and that's a point of weakness. You can't turn on multifactor authentication there because then I would be having to ping you Tommy like, "Hey, I'm going to log into something." Tommy's like, "Oh, MFA is turned on. I got to go." It just doesn't work. It's just so clunky. I don't like the experience of it. Does that make sense, Tommy? Mike, I've seen teams where they had to log into their browser with that user account. I'm like, what are we doing

[9:20](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=560s) Here? Yeah. I think I think people understand the concept of a service account, but how it's implemented, I don't really love it. Right. It that's what the workspace identity is. The the workspace identity is the service account that we should be using to get through different elements. So anyways, okay, enough harping on that one. Tommy, you've got a couple more news items here that are worthy. Let's go with one of yours. Yeah, so this is going to be one article from Microsoft, but then one from we haven't done a article from in a while from Chris Web. So, okay,

[9:50](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=590s) Drill through and Excel and just so if you heard me correctly, I did say Excel now is supported for direct lake and direct query models. Oo, this is interesting. So really the limitation before was if you wanted to get details in Excel when you were doing the analyze your data you couldn't do it with a direct leg or direct query it was only an important model now that barrier is completely broke or or finally crossed and that

[10:23](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=623s) Showed details with using our old fun language MDX to be able to see that additional inputed data So PowerBI supports the drill through enabling you to double click on your pivot tables and retrieve the underlying data and it's available just out of the box. No additional configuration that you need to do and it works with row level security and object level security configuration. So it's still giving the context to the user and passing that through. Tommy, do you use a lot of drill through inside Excel or or using that

[10:56](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=656s) One world? it it's not a universal catch- on, but I I'll put it this way. The teams or people that do use it use it extensively. So, it's it's more common than I it's than you would think. It's not like only five people use it, but it's probably maybe out of a hundred people, I would say 20 people in my organization would be using it. Maybe 15 to 20, but they use it for their work processes. they that's part of their workflow.

[11:28](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=688s) Okay. and just being able to connect to the data and then work off of it. So this is really I think for those people especially that we're moving that direction anyways. now this is going to be one of those where people stand up and cheer. So one thing I'll just note here as well is when Kai Kai is the principal PM on this one or at least working this feature through which I'm very excited. Kai's amazing. Does a really good job on things. I love his thoroughess on features and he's a great PM for features and things. One of the things

[12:01](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=721s) He notes here at the beginning of the article, Tommy, that it says, "Historically, show detail relies on MDX drill through statements." He never really rectifies or resolves that statement. All he says is it now works with direct query and direct lake. So my question is is did something change on the Excel side? Is it not using MDX drill through anymore to do these queries or is it now the model has changed and now the model is able to accept MDX drill through queries on direct lake and direct query.

[12:35](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=755s) When I read this article, I was initially thinking and I read it three times here while you were talking Tommy just to make sure I got it in my head. It sounds like the semantic model has been updated to handle the MDX queries that Excel will fire to it that will then let you drill in and see the details of the table. I was initially thinking that Excel was getting an update so that it's not running MDX queries anymore. Maybe that's true, but the way the article is written, it doesn't indicate to me like when you say the word historically. Yeah. It makes me sound like that was

[13:08](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=788s) Like a legacy thing that was something that was previously there and now it's no longer there. So I may I may put here in the little comments down here in the discuss area at the bottom and say hey does this mean that the direct query and now are still using MDX or is this something else that we're are we going to see a new language? Has Excel been updated to have like DAX language now? So I don't know. I'm not really quite sure. yeah the chat is talking here. Yeah, Chad I'm agreeing with you. , I would like to see the Excel pivot table generate DAX instead of just MDX, but that's

[13:41](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=821s) It is what it is and that's how it works. So, I don't know if we're going to Excel, I find, is a monstrosity of a beast. I don't know how many users are actually inside Excel. , Tommy, but I'm guessing we're north of a billion users using Excel daily or monthly. I'm doing a training next month for Excel and I I my only request was can we with a client I'm like can I do a scoping to understand what they're trying to do with Excel because there's a very that's a good idea great idea it's very you can do a lot of things with Excel

[14:13](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=853s) And a lot of times too they go we have all this data that we're trying to go around like well do I have a thing for you? Yeah, I have a new tool. Yeah, you may. [laughter] I'm also doing some training here recently, Tommy. And one of my big stories here is I love the fact that Excel has Power Query and PowerBI has Power Query. Those two items are amazing. , and the fact that those exist in both places, I heavily emphasize automate, automate, automate. And I I'm shocked, Tommy, the number of people, I

[14:46](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=886s) Mean, Excel Power Query has been built into the product for a long time now. Yeah, like since 2017, 2016 somewhere in there. I don't even remember. It's been so long. Power query. Oh, you mean like without it being a plugin. Without without it being a plug in built into the tool. Yeah, but you had to make the addin before. So, the fact that this has been around so long and I have and people are still downloading data from the internet in CSV form, copying it out and putting in their Excel file to reformat it is just beyond me. I'm like, Microsoft needs to do a better job of educating here. Like,

[15:20](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=920s) This is something that Microsoft should be highlighting in the tool. Look at this Power Query thing. It's amazing. You need to start using it in everything. And I even do a demo where I build some Power Query inside Excel, load some tables, and then I do a onebutton import directly to PowerBI because you can directly transfer the Power Query language right into PowerBI stuff. So like if you start so my argument is no matter what you're doing, you better learn Excel and you better learn Power Query because that's the most that's is the strongest tool that you're going to get your hands on that can do data engineering. You do not want

[15:51](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=951s) To manipulate data inside PowerBI or sorry inside Excel. You want to manipulate it in Power Query first, then get it into tables, Excel, other places. We always bring up Excel and I remember at my first company worked heavily with the sales team and the amount of Excel files that were referenced with formulas with business logic and just to try to go through this Mike people were not just doing some functions. , these were very smart

[16:24](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=984s) People with a very terrible organization skills or there's really nothing else you can do. But it's amazing till to this day, Mike, organiza, there are organizations out there who make money, who still make money despite of it, who are relying on ridiculous functions and on certain cells and certain references just to get by. Yes, I totally agree with that one. Chat is getting quite interesting here. Tommy someone Milhouse is is saying I wish I had an Excel table

[16:57](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1017s) That would use the combo filters and query fold back in PowerBI. Tommy, I'm going to tell you right here. This is my dream right now in in PowerBI. Okay, don't say the same thing we've said every so many times. I probably am going to say heard the the the tape there needs to be a slicer table visual. just has to be like to me there's just no reason why this doesn't exist. Why can't I put a table into PowerBI and have it function the same way as a slicer where there it is,

[17:29](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1049s) Right? So why can't it function the same way? I have a table with columns and data in them and I apply filters directly to the columns. The table gets shorter just like it does in Excel with a table. Those should also be applied back to the rest of the the model there as well. So anyways, what also I want? I also want when I scroll through that table to make it feel like it was Excel, too. Why can't they do that? That was another thing we brought up probably three years ago, too. I don't know when they're ever going to

[18:01](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1081s) Get to it. We really definitely need some like big improvements around the Excel file like Excel like tables experiences. If you just brought that experience over to PowerBI, I think you'd make a lot of people really really happy inside the PowerBI space. But Mike, don't worry because they Microsoft's been working hard and they just updated the card the image visual in PowerBI which is I've also found that to be quite interesting. Tommy, have you used the new card visual like it's it's now updated and this the it's the default. Well, I've also observed that in

[18:35](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1115s) Older reports when you were using the old card, it doesn't highlight it anymore. Like so let's say you have an old report with an old card and it's not there like it just doesn't exist. You mean and you can't find it. Yeah. No, in the in the pain the pain does not have thing. That's that's what I'm saying. And you click on the visual like what's happened. Yeah. And I was like this is weird that it's it's the old visual but they're not showing you that it's there and then you have to go click the ellipsus and say show all visuals and then it shows up.

[19:08](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1148s) So, it just feels like if I select an old visual that was there and you're no longer showing it in the filter pane, we need something to like indicate like, hey, this is the older version. Would you like to update to the new version? Yeah, I would have at least expected like a message box on the old visual. So, the transition from the old visual to the new visual was really caught me off guard there a little bit. They did that with the Azure Maps visual. You got to enable this or upgrade that. But, what? I I bet it is, Mike. That card visual is so ingrained in probably so many reports.

[19:40](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1180s) Oh, 100. what ? Like this is everywhere. This is not a feature. This is, , this is like changing the plumbing. , it's a bug by design. [laughter] Yeah. Yeah. Yeah. If that has to be the most popular visual and and if PowerBI to look at their every report ever created. Yeah. I don't know, Tom. That would that would be hard. , I think I think that's probably a very high visual. I think the other visual that's extremely used would be slicers. No. And no way.

[20:13](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1213s) Yeah. I'm I'm I would argue I probably argue is like slicers. It'd be nice if we could get someone to tell us like what what was the most used visuals, but t I think tables and I think tables and slicers are high up on the list in my opinion. , [sighs] I I obviously would regretfully agree with you on the table one, but for whatever reason, I don't think it's going to be as high as you think. I know every T report has them, but the volume of visuals, you really think the real estate people are still putting slicers everywhere?

[20:44](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1244s) Okay, here we're going to have a hot debate here real quick. All right, let let's think about in the early days, Tommy, when we were building things. Well, let's even with the filter pane, the filter pane exists. I don't think a lot of people like it. I don't think a lot of people use it. I think it's a an underused feature. The filter pane I think is extremely powerful. I like it. I think it's really good. I like using the filter pane for a lot of filtering options. Not many people agree with me on that stance. However, think about this, Tommy. Whenever you build a report, which visual is the one visual you're going to at least put two, maybe three of them on the same page. And it's

[21:16](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1276s) Usually going to be the slicer. You may put a bar chart on there. You may put a pie chart. You donut chart, whatever. Don't love it, but you might do it. And then you put a table, right? So these are these are, , you'll you'll have one or two of the other visuals on the page, but I can't tell you how many reports I've built where there's been like three, four, five slicers on the page just to filter multiple columns. A date filter, a category filter, a region filter, like those are always on every page. And every time I go into companies

[21:48](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1308s) That are newer to PowerBI, the first thing they're trying to do is how can we get all these slicers on the page? Where do we put them? What's the design of the page look like so all the slicers can get there? So, I'm pretty confident like the slicer is high on the list. Now that you're saying that and I'm thinking about all my reports. Yes. Go back to your early days. No, I'm today too like there's now they're not as loud as they were, but they're still there. So, I think that's that's the difference between a seasoned PowerBI Pro and a new

[22:20](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1340s) One is how many slicers do you have on a given page? Yes. So, yep. , especially those who are coming from Excel, they want to be able to edit everything. It's funny you say that with the filter pane, too, because I really try to use it, but it's kind I use it all the time now. It's It's my go-to for everything I do for filtering. Filter. Yeah. , I like to think of like the report as like an interactive thing. So, if I need a slicer or I need something to slice by, I put a visual on the page that allows me to slice. So, if I want to slice by a certain thing, to me that indicates like this needs to be

[22:52](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1372s) Like a bar chart or some element on the page that I can click with my button, my finger because I also feel like especially when we're talking, let me let me speak personally about my business, right? My business, I do a lot of moving around and I travel and I speak and things and so sometimes I need to go see the PowerBI app. I use the PowerBI app a lot on my phone, believe it or not. And so by having the app on my phone, I can easily click on data bars directly in the app. And it's nice, it's graphical, like I can click on the bar and it filters the data down. So a lot of things that I'm doing filtering wise is

[23:24](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1404s) I'm using the the report itself to filter what I want. So I feel like the natural interaction of the report is a slicer by default. So I try and think of slicers in the way of what visuals can I put in place that are easy to click on that will then give me the same interactions as a slicer. And then anything else I want, I put on the filter pane like years, dates, people, all the other things that we need to put on the side, that's almost always relinquished to the filter pane because I get so much more control. I can do pick list, I can do search by text, I

[23:56](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1436s) Can starts with contains, all these other different filter options and I don't have to rebuild the report just to get those functionalities to work. I do agree with you, Tommy, that the filter pane could probably use some additional love. It it could always get better. I think there's there's experiences there we can make much much better for users. I'd also like the filter pane to be able to be on the left or the right. Right now you can only get the filter pane to be on the right side of the report. That's all you can do. So I feel like the the filter pane itself needs some additional featured options so that when you're publishing reports you could

[24:27](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1467s) Actually make that move between left and right sides of the report as well. Again maybe even top or bottom. I think I think you should be able to place the filter pane wherever you want on the page and it should just work no matter what. But anyways, I like it. I think it's a good feature. This is great. All right, so let's go to the last article that I have. And I'm gonna give a shout out here to Mr. Christopher Webb. And what we are dealing with is stopping PowerBI report or stopping PowerBI copilot from answering questions from

[25:00](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1500s) Report visuals. So this is interesting. Yeah. What's this all about, Tommy? So when you ask a data question in PowerBI copilot the first thing it's going to try to do is answer question using an existing report visual. So you ask a general question it's going to basically go okay let me see what visuals are there and we'll just reference that. If no answers found then it will generate an actual DAX query or create a new visual. So the report visual is obviously the most

[25:33](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1533s) Reliable way to get an correct answer, but depending on the measures and the filters, visuals can produce misleading or very incorrect results. And you can see this how you tested it. , so that's where the AI instructions come in to control how co-pilot answers questions because there's still Microsoft hasn't given a ton of examples and like different scenarios for the instructions in a semantic model. And I this is a great one where with your

[26:06](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1566s) Instructions you say ignore visuals for anytime a specific measure is referenced by the user. ignore all the visuals on the report page instead always generate new visuals. So which is pretty cool that you and you can get to that level of detail with the instructions and it will in a sense respond and abide by that. Yeah. So this is basically changing the prompting that's using being used for co-pilot. , it sounds like this was a a blog post that came from Chris Webb. , but , Cecilia Bis was the one who

[26:40](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1600s) Came up with this notice here. And it it feels to me based on what Chris was writing here is there are visuals on the page that the AI is aware of, the co-pilot is aware of, and it favors, , if you're already asking information about what it sees on the current visuals on the page, it's going to read that information and just put it back as text. So you'll note here and Chris highlights here there's a little annotation that comes with the responses number one saying hey this is where this is this is the reference point right so

[27:12](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1632s) Here's how we reference this information to get you the answer here and by using this prompt if a user ask a question about the average price paid measure ignore all visuals on the report and do not use them to answer this question as they may give a misleading answer instead said always generate a new visual to answer this question. So having that prompt forces the AI to not use the visual layer and go directly to the semantic model and then it uses the semantic model and then what he shows you then is look when you use that

[27:44](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1664s) And you ask the same question it now produces an actual data card and recalculate something for you automatically. So interesting concept here, but Tommy, this is the stuff like how my my problem with this is how do we ever like how do you figure this out unless I was like unless right unless I'm listening to the explicit measures podcast, unless I'm doing work with like this particular feature when when are we going to figure this out? And my my complaint here a little bit is a lot of this co-pilot stuff is

[28:17](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1697s) You have to experiment with it. You have to write queries against the model and see what comes out. Where's the education on this? Where are people like this is? I don't know how to say this a different way, Tommy. I'm what I'm trying to say is it's hard to understand a non-deterministic solution of what it's what it's what it's popping out. What is the what is the information? I don't understand it. Does that make sense what I'm describing? No. So here's the funny thing that I wish Microsoft did a better job is whenever they introduce a new not just tool but a new in a sense concept. a

[28:52](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1732s) Lot of the AI teams I think they have people just dedicated to unless AI is doing it for them I don't know but they have teams that are dedicated to building out like in a sense scenarios sandboxes and doc and like basically this guidelines. So Tommy, honestly, take a look at everything like Cloud Code is doing and it's, hey, we have this new thing called Cloud Skills. Never heard of it or never knew why you'd need it. Okay, here's all these community, , GitHub cookbooks

[29:24](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1764s) That we've developed on reasons why you'd want to use it. GitHub has now agents that you can actually connect to your repo in and have instructions that can do different things. , I do use that. Yeah, we we actually use that in our company. Yeah. direct. We directly use co-pilot to do reviews on code and it's getting it's getting really good at reviewing people's code. Hey, I see that you made this function twice and it's repeating. You should probably turn this into a a function as opposed to having the code the the business logic being repeated in multiple areas. So that I get Tommy but

[29:58](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1798s) Saying that you're going to hire someone there definitely is some level of like QA and QA testing. I feel like the more efficient way of getting to this answer is building a test bed, right? No, it's not testing here, Mike. This is the marketing of it to get it out so people can start using it. That's what I'm saying. It's not this the we're building thing things community open- source resources you can start downloading and using. And we need to give a ton of different scenarios for anyone who's interested in this to go,

[30:31](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1831s) Oh, , you can use this to build make a PDF. You can do this to do a presentation. Here's all the ways you can utilize this tool that you have no idea what to do with or where to start. And and most of these AI companies, especially because they're introducing not just like a new car that how to drive, it's like, well, do I sit in that car? How fast can I go in that car? These are people who are dedicated to basically understanding like all the different CA main cases of who's like their personas and getting started with

[31:04](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1864s) It. So people go, "Oh, I didn't know you could do that." And I think this is the hardest thing of of our industry right now. It's amazing what Cloud Code is doing, what what Google's even doing, too. Go look at any of the cookbooks on GitHub. it's ridiculous. But for us with the freaking AI and fabric IQ, here's co-pilot or instructions for a semantic model and not sure what it outputs, not sure the value. I just know it's a giant text box.

[31:36](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1896s) But this is this is my point though. You're talking about like a car and how to drive it. That's all deterministic. If I press this gas pedal, this is how fast I'll go. All that can be learned and the inputs produce a very consistent response. What I'm struggling with here is how would I even know to do this article from Chris Webb without reading the article from Chris Webb and discovering like I made a prompt, it went against the model and the model returned something I wasn't expecting. So you have to be able to identify. So my

[32:09](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1929s) Problem here is because these things are very like specific. The rep every every report the AI is going to go against is going to be different for every company. So how where is the collective knowledge being gathered around what prompts or what instructions should I be sending into the AI agent the guidelines what best what are those things what are the prompting things I need to send to the agent so that I get a good or consistent result out and also how am I getting feedback from users

[32:41](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1961s) Using my agent of like hey this thing returned a value if it's if it returns so for example in Chris's article, it talks specifically about something coming back incorrectly. Like that scares people, especially in the BI space if you're going to make decisions on something. , what did he say here in in the in the note here? He said, , oh yeah, in in the prompt itself, right, if a user asks a question, it says , do not use the visual because it may give a misleading answer. And I I'm looking at that going, that's scary to

[33:16](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=1996s) Me because that's letting people prompt it and it's not getting to the to the right answers that are in the report. Any if if it comes back misleading and people are making headcount decisions based on a misleading answer that was prompted back through co-pilot, oh my word, Tommy, heads are going to roll. So this is where I I'm very interested and like again I just don't know where we learn all this stuff. Like this is a lot to me. This feels a lot of like experimentation. Everyone's trying to figure it out. We're all trying to learn

[33:48](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2028s) Together how to get this AI to work better with their reporting and to have things that come out like this just make me extremely nervous. I'm not a big fan. Yeah. So here I want to send you an article just for reference, but this is what Microsoft should be doing especially with things like this giant copilot instructions. It's like rather than just write it what you want it to do. This is and this is just the blog which is ridiculously huge. It goes through hey what is it? what how do you get started with it and then what are like what are some of the techniques

[34:20](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2060s) You can do right where oh by the way if you say this it's going to listen and there's all those hidden little terminologies that you can do. this is a good place to start with some of this but again we don't even have that you you don't even get to see these things. you don't even get to see like you don't know these things exist until an error happens and that's my that's mainly my complaint here is sure yeah because it's so easy to get that's the advantage of it it's also the disadvantage of it right the

[34:51](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2091s) The one reason why you like AI on top of things is it's very creative right it's it can get it can interpret your question and interpret data summarize both of them and get to an answer that it thinks is the best answer that's really helpful that's also its biggest Downside is you may ask a question of it and you're trusting the answers that's being provided. And unless you actually take a critical mind and go in a little bit and say, "Okay, this is the answer it's giving me. Does this make sense? Did the AI agent provide proof that this is what we're actually talking about?"

[35:26](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2126s) Then then I can have confidence in the answer. So this is this is the part where I'm a little bit leerary about this. And this is why I like using AI agents with code more is because you can test it right away. Right? If I'm if I'm asking an agent to write Python for me, it may not write the correct Python or the most efficient Python, but as soon as it writes the Python, I can go to my notebook. I can run the code and see if it works. If it works, then it's right. If it doesn't work, it's not right. Now, it may give me mixed results that come back. I can evaluate those as well. But like to me

[35:59](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2159s) That feels much more testing the answers that are being provided from the AI versus when you're looking at reporting I'm asking a question. I don't have any way of there's no method for me to test that answer. Does that make sense? No. The testing parts me that and that's what to go back to my initial statement. I guarantee you these organizations on the forefront of technology have teams devoted to literally like the people who tested video games they are just all they're doing is trying things out and then they generate this nice little blog

[36:34](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2194s) Article cloud didn't know this until they went through it too but they have people who are dedicated to literally trying to figure this out and find those bugs find the weird hallucinations yeah but for you and I, Mike, we don't have that. This is the same that happened with when UDFs came out. You remember there was that one like weird GitHub page on Markdown that didn't really explain much about the different userdefined functions you can have. Like it was pretty bad. It was it was a more code than it was a documentation.

[37:09](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2229s) But for these new features that come out for trans analytical workflows, I'll send it to you. , right. There should be a ton of different examples and not just a GIF moving around the screen of, , Jim's going to be doing this and all the ways that you can implement it so you can get started and know why you're going to put the time in. Anyways, I think I'm beating a dead horse there. Yeah, I'm not sure where you're going with this one, but okay. Oh, what I'm trying to say is we are on the forefront of You don't have to keep going. I don't understand where you're going. We We could just move on, too.

[37:40](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2260s) All right, let's move on. Why could you explain it again? It gets me frustrated. Okay, sounds good. All right, so let's move off of our main news items here. So, those are some good news items around those topics. Let's jump into our main topic today. , we're going to we're going to use an article from Microsoft. Let's unpack a little bit more around what the fabric IQ is. We've talked a little bit around this new released feature from Microsoft Ignite. Let's unpack this. Tommy, let's what do you think here? How should we frame this conversation with this article here? introducing fabric IQ for the

[38:13](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2293s) Enterprise and yeah we are really going to be breaking this down as well when it comes to from the governance side. We did introduce this a I think last week just this new introduction of the fabric ontology and now we have what is fabric IQ which is really a foundation of your soft and hard data how the organization speaks conceptualizes and really brings all their information together and really geared towards the new AI

[38:46](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2326s) World that we're actually running into. it's all of our data, not just my data and SQL, but all those PDFs, all those things that the teams work on. All the information that an organization gets their hands on is has a single estate in place for us to not just connect or interact with it, but also to make sense of it and how it relates to everything else in the organization.

[39:18](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2358s) I think this is a precursor. So let me let me give a bit more context here. So we're talking about let's let's just step back and not talk fabric IQ. Let's just talk about the data that exists in your organization and where that data exists. I think that's a good place to communicate here about what fabric IQ is trying to accomplish. I guess this is my understanding of initial runs with the program and and what's happening here in Fabric. So when you look at the blog post there's another blog post here talking about from data platform to intelligent platform introducing the Microsoft

[39:50](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2390s) Fabric IQ. This was on November 18th that was announced and the idea here is data [clears throat] needs to become understanding and then they're they're shifting this idea of being Microsoft Fabric IQ is semantic intelligence platforming. So it takes all of your semantic models, the relationships between your data tables. This is called an ontology. It's talking about AI foundry, Microsoft 365 copilot, databases, real-time intelligence, graph databases, data agents, like all the

[40:23](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2423s) Things that are required that Microsoft's pulling all these tools together. What is the unifying methodology or , why do we care about pulling all these things together? And I think that's this is where they're trying to come out with this idea of you need to have the raw data, but then you also need to have relationships in the data. You also need to be able to define master data in your organization. And I think that's where these this idea of a intelligence platform is coming

[40:56](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2456s) From. So that's that's my framework there. What do you think? And this is much different too when you initially say that I have haunting memories of purview and things like that. Yeah. Where the difference here is it's not just being able to in a sense view my data and see where it is but that next really human level of a shared definition the lineage and really what goes into those pieces of information. how they relate to one another, how they

[41:28](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2488s) Act on one another in a really new different type of semantic foundation that we have not seen before. Obviously, we're still using something that looks very similar to our semantic model, but I think our example that we gave last week was if I've been looking at two 2D paintings, Microsoft has just introduced a new painting that's just simply 3D. so we're adding another dimension to what we're already doing. And again the key benefits why is Microsoft doing this. Well we are moving

[42:02](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2522s) Into a world of AI. We've quoted this before. U 90% of organizations right now who are trying to adopt AI are failing. and there's a lot of reasons for that. One of them is again, okay, what's a universal way that we're going to make sense of all the information that we have? And again, to your point, Mike, it's not just my data that's coming from a SQL database and this other data source. It's Yeah, I want to expand on that. Like, so I

[42:34](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2554s) Think this concept of like the ontology is Tommy, we work in multiple places. We have files stored in place, we have files stored in SharePoint, we have PDFs, we have slide decks. there's there's a lot more information that's at our fingertips in our organization that we're making creating we're generating this data and putting it somewhere. So when I look at this experience here and what what they're trying to do here, I think there's this concept of okay, a lot of the language here, they're talking about unifying the platform, bringing everything together. And so this is where I want to unpack the governance part of this a

[43:06](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2586s) Little bit, which is how do we get through this concept of governance? Like what is this what is this going to look like? And I think because this is new and we haven't figured out how to use this ontology piece yet, I think we're going to have to start small. I think we're going have to start in like a team, a department, something a bit more specific and then figure out what works for our business and then grow it from there. But, , as soon as you start talking data governance, there's this whole idea of who owns it, who owns the master data. , if there's information that's

[43:38](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2618s) Incorrect that's being brought into this knowledge base, what happens when something's not properly described? It's not fully fleshed out. the Excel document has wrong errors and formulas and issues inside it. Whose responsibility is it to correct that information? I think there's a maybe potentially a false mindset here a little bit, Tommy, that when you read these articles, it feels like, oh yeah, all this makes sense. Pull all of our data organization together,

[44:10](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2650s) But we're also assuming that the data is 100% right and correct and ready to go and cleaned up and and ready to be used by AI. I I don't I don't really get this this this feeling of like, well, how do I some [snorts] data needs to be brought to the central fabric IQ piece, but at some point you're going to find bad data or stuff that's not right or things that shouldn't be included. How do you how are we going to be able to kick data out of that as well? So that I feel like there's there's the data governance piece here comes with some additional considerations around who needs to manage it, who is the

[44:44](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2684s) Authority of whether something is correct or not correct. We're going to need to have more organizational conversations around if we're bringing data to the ontology, I think we're going to need to have a data owner for everything. A data steward for every single piece of data we're bringing in here has to be established before you bring it into the ontology. What are your thoughts on that? , it's funny that you say that, too, because in the blog article that we're referencing, , at the end of it, it says, "Hey, check out the release plan for, , Fabric IQ," which

[45:17](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2717s) Obviously is one of those most exciting ones. Sure. Well, it turns out that's the fabric road map just filtered on administration, governance, and security. So, hilarious there. That perfect segue there. It's lit. Yeah, it's not like a separate fa fabric IQ roadmap. It's just the same one. So obviously we're on the same page with Microsoft as always and and Mike. Yeah. Again, this is something where without getting too ahead of ourselves,

[45:49](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2749s) We are now introducing again to the organization where we've already try to hammer home, hey, can can I get these definitions from you in order for AI to really have an effect and be, , an effective part of an organization, it has to have a shared sense of what something means here is the same thing it means here and this starts with our governance and it starts with our just making sure that everyone can be more than just on the

[46:22](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2782s) Same page but that information is where it needs should be. So the problem right now with if you look at the AI world and it's not even just for enterprise is the lack of unified language. For example, we just talked about the co-pilot instructions, right? Well, those co those instructions are different for co-pilot than it is for another AI tool in terms of the format, the structure where you have to feed it. So, we're dealing in a world where there's not a

[46:54](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2814s) Lot of in a sense structure best practices already out there. This next level is we're doing this with a business or or each business with their soft data. Mike, we're bringing in now all of the concepts that they share to your point, not just the powerpoints, but the POS, the things that really never touched our department in the past. Maybe we try to extract some of I'm going to maybe slightly maybe not disagree with you here, but maybe I'm going to also like I don't think all of

[47:26](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2846s) Our data needs to be part of this. Like I you keep saying the word all and all our data and everything's here. I don't think I don't think it's a fair statement, honestly. I think that I think we're going to have to be selective as to what we bring into this ontology space and and not bring and it's not this assumption of like we're going to absorb everything. I think that's a naive statement around bringing like that's not the assumption here. I think what we're going to have to focus on is very narrowed things that are useful to the organization and hyperfocusing on building solutions around key areas here. So like I guess

[48:00](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2880s) Maybe another example another way of saying this is a lot of the example Microsoft gives here is like airplanes airport hubs like there's very specific inputs and actions that need to come out of the data. So I think you don't want to come into this ontology space or this this data governance space and just start throwing things at the wall. It's not like hey here's a bunch of things we're just going to throw it at it's a magic it's a magic fix here. Yeah. I think there's a whole strategy that we're going to need to like sit back and think about is okay what are the at the end of the day what are the key actions I need to take

[48:32](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2912s) I should ask another question around what is the speed of those intera those acti actions from when the data occurs how fast do I need to action and make decisions about things some things can be moved quickly like again like go back to Microsoft's example in the airline industry we can quickly move people around from planes, gates, like that's a fastm moving data space and you need to have that information quickly. But in other areas, like if you're looking at like your sales pipeline in a

[49:05](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2945s) Day, you're probably not going to be able to make shifts and changes on the sales pipeline in a day. You're going to need some days or some weeks to get through that information and allocate new people or hire new sales representatives. some of those changes are much slower but you need to be identified is at the right time to make sure you can make the right decisions around those customer-based informations. So this is where I think the data governance is going to become increasingly important here especially in the ontology and I don't again I haven't seen it in the ontology yet today but there's no concept of that I see around bringing things to the

[49:40](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=2980s) Ontology and then applying data owners or data stewards to all this as well there there there's going to have to be a better cataloging experience and I think as teams unpack does this feature make sense to them we're going to need a concerted effort to identify where when data comes into ontology who are all the people that need to agree upon this is the right data to bring into this sitting back and thinking through these are the actions I'm expecting to take using this ontology right because I again back to

[50:13](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3013s) Our point what we said a lot of time before Tommy with reports if the report isn't making money or saving money why are we doing it so just to throw down an ontology in hopes that the agents can use it I think is a bad way to build a system. So, I I don't want to get off track, but you bring up a great point here in terms of how to we're going to approach this because right now and just for my own state of mind right now, the goal of any antology model or the ontology artifact in fabric is really to

[50:48](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3048s) Use it with a data agent, right? Or what and that's Yes, maybe. Is there any? Yeah. And is that the only output? So let's say you [clears throat] have your ontology built well what can you do with it if we have all these def shared definitions and we've raised all the entities and they have meaning now and all those things. Well, when I finish that, so to speak, the that's be is that just for an an agent like either the operational agent

[51:23](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3083s) Or the date agent right now because you can't really do anything else with it. , they're talking about action based things. So, if you look at like the ontology piece and they're talking about something happens and so part of the ontology piece is alerting based on data coming into this ontology, right? I have streaming data coming in. We have certain thresholds that we're trying to meet. If we don't meet a certain threshold, go send someone a message on Teams, right? Or go do something, right? So, this idea of like actioning on top of your data is a message that they're trying that I'm hearing they're saying

[51:57](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3117s) Throughout this fabric IQ. Now to your point also Tommy right this this idea of linking different semantic models PDFs instructions business product information not all of this exists in nice clean structured tables is is also part of this right so having an AI agent understand these are our products and here's the PDFs or the marketing information about those items the agent is then able to traverse this ontology and say oh you're asking questions about product details I can go research what product it is and go pull documents to

[52:32](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3152s) Make the AI support those in whatever it's doing. So I I think the idea here is you're you're try to your point Tommy right part of this is letting the agents have more information but again we're back to our same question we were talking about with the Chris web article. How do I have to write really clear descriptions of things? how how much of pre-training prompting am I g have to provide to this? Yeah. Just to make sure that it doesn't give out weird answers, right? So, along those lines.

[53:04](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3184s) Yeah. And I just sent you a link and I'll I'll make sure that's in the episode description, but window. Yeah. get get into the chat window when we're thinking about ontology at least is which the foundation of fabric IQ is this also helps us when from our governance point of view on where we're actually going to attack first right in terms of hey organization everything we have to do we need to start defining it well we're going to start with who's in the

[53:37](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3217s) Biggest need of action and to your point probably a plane probably sales and then tryh tackle it from They're doing their tables again, their table of choices, Microsoft is. And it's interesting that they're taking ontology and basically putting as a level with what a semantic model is. So basically what we're looking at here is when you're choosing the right tool for a scenario of in a sense getting your head around information they Microsoft is proposing the ontology artifact

[54:12](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3252s) Graph and Microsoft fabric a PowerBI semantic model and they all have a different use case for depending on what you're trying to do. I'm intrigued that they're finding them all in a sense on the same playing field here. But it makes sense. And I think for us when we're going to say one, we're not just going to dology because everyone's asking, it's who okay, let me let me ask you this. When it comes to everyone clamoring for let's say everyone wants fabric IQ, they

[54:44](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3284s) They love it. They love the idea of it. they just want AI to work for them. From the governance, I think it's also choosing that team first. I you you mentioned that we probably have to start small. Well, what are going to be your prerequisites or the things that are going to be considered for an organization to dedicate the resources for a particular department or team? Well, I I think I think your your statement there is a little bit

[55:15](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3315s) Backwards in how I would view it. what the business is asking for. I I would say the business is asking for we want to use AI. We want to put agentic things on top of our data. That's what they're asking for. We're being the everyone is saying I'm looking at all my Twitter feeds and all my LinkedIn messages and I can see people building entire apps. This is this is literally inundated with my feeds now. I must be watching too many of these little short videos of people like, "Look at me. I created an app in 16 hours that now creates $10,000 of revenue each month." Like I'm like

[55:46](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3346s) Thinking to myself, this is not real. This is this is [laughter] a bunch of lies. I don't know what you're talking about here that there's no way that real people are actually doing this. This is like the the most curated experiences of very small people. So I don't think that's real. maybe it's happening, but it's happening in such small doses it's not not really occurring. So when I look at this AI space and what's going on, I think people are trying to say look we see all these things on social media therefore we think we must use it. Mhm. Microsoft, what's your answer to all this agentic stuff? , I can

[56:19](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3379s) Use these different products. I can see these different tools. There's all these nodebased development systems. Microsoft, what's your response to this? And I think this is Microsoft also saying they're trying to figure out their way with agentic things as well. And we're in this space of it's everything is going to be evolving very quickly. And so because the agentic space or AI space is moving so quickly here, I think we're going to have a hard time adopting ontologies or or this fabric IQ space because what it looks like today will probably look totally different in six

[56:51](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3411s) Months from now because of new technology, more efficient ways of doing things. , again, this is all like a discovery mode. We're all learning this together, figuring out what's the best place to put AI. So I think that's what people are clamoring for. The business is clamoring for I see so much AI, we need to use it. How we use it or what's adding value in using AI, I think is still to be determined. We're still trying to figure that part out. I've had some conversations with my engineers.

[57:23](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3443s) AI agents are really good when I build the software, but sometimes they get stuck and they can't solve a problem. And the amount of time we're wasting writing a more detailed prompt to explain to the AI to fix something would have been just faster if I just went to where the problem was and looked at the code or whatever it generated itself and just go fix it. So I while there are certain aspects of AI things that are making it very easy for me to generate things like my Python function or some specific things

[57:55](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3475s) That makes sense. There are other situations where I'm spending more time prompting than actually getting the work done and waiting and waiting. Right? So there's there's this balancing act of like what's going on here. So I think ontology and this idea of relating more information together is to give agents a better chance to provide better information back to users. And we're not there yet and we don't have good patterns yet and it's still very to be determined. And I think that's the the magic word there too because I know

[58:27](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3507s) Exactly what your developers are are feeling. And that goes back though too with the space that we're going into doesn't have a universal way of in a sense organizing information right like we don't have that the patterns yet where hey best pra like everyone if you are going to build a SQL database for a company there are books there's the best practice guide to make sure that things to optimize it for organ the organization of it and right now we're looking at AI

[58:59](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3539s) Guy like just feed a web article at it and he'll read it. Trump works for that one off, but when you're doing this for an organization, there has to be in a sense those that that shelf of information that's organized correctly. So, an agent can go, oh, someone's asking and needing something here. I'll go into drawer two, get the required context, yada yada, then act on that, which every, , like every app or every tool is trying to do their own way of it. But

[59:32](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3572s) Microsoft's really realizing like that's not going to work for each unique organization. So, can we create in a sense that's really what this is that unified shelf of best practices that everyone can speak to? And I I would agree with you the more we talk the more we go through this is will this be the final solution here? Well, there's got to be some use cases and we'll go back to what I said. There's they've got to show this is more than just for a data agent that I can talk to. , and we're like I see what

[60:09](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3609s) They're trying to do to build the foundation, but if they actually want to see organizations trying to do this because we haven't even talked Mike about the the human side of this the governance around getting people's process around the definitions and everything like that. If you're not even there, Microsoft just understand what are the use cases so people can start actually looking at this and adopting. So yeah,

[60:41](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3641s) I I did not land that plane by the way. Yeah, I'm having a hard time following what you're saying. Yeah, I think there's just a lot more coming. I think the the ontology and the data governance piece is very new to the space. I think what it's trying to accomplish here. or so from data governance. I really think in this space we need to start small. We need to start with small use cases that are very actionbased. Focus on building ontologies and very specific use cases around what this is going to look like and then be very careful as an organization as you're bringing knowledge to this ontology. I

[61:14](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3674s) Think you're going to need to have data owners and that way you have at least a conversation around who needs to own the information and who needs to be able to push that information into or if there's an issue like there needs to be a ticketing system to some degree, right? When this thing is wrong or when we're getting some weird results, someone needs to be able to ask a question. Is this really right? Does this really produce what we want? , and then we can go back and what's going to have to happen is there's going to be some level of testing, figuring things out to get down

[61:47](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3707s) To what is the root cause of the error. And maybe there'll be an agent to help us with that. I don't know. Maybe there's something that will be able to build an agent to help us comb through the ontology and figure out if there's weaknesses or problems or issues in it that we can fix. But, , there's this expectation of what people want to do. And I think if you're trying to remove there's something healthy in the process of learning working with your data to get to an answer, right? It helps the user have confidence that they've done

[62:19](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3739s) The right steps to get to an answer. If you take all that away and just have people blindly trust the AI, I think you're going to run into problems. 100%. And I would like to apologize to you and everyone else. I think I just had the longest brain fart in my previous statement. Well, I I know. So, focus on your idea. I know. I I had a few ideas and I wrote down like, "Oh, this is going to be a great way to land it." However, land one idea at a time. It's a lot easier for me to follow. It all got scribbled into one. So, I I want to apologize. That has not happened in a long time. But I I think

[62:51](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3771s) Yeah, Mike, I'm just gonna did what you said here. when when you look at where should you start if I'm listening to the podcast hopefully still and you're like okay I'm a director of BI I'm a data analyst whatever you're doing it's like let me try this out where do you start start with the most blatant use case of where you can see an agent helping you out because that is the outcome right now that may not be what ontologies down the road but just

[63:24](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3804s) Start with some like wow if I had something where we could get our POS done just by asking a question it would pull all that other data that I information I don't have that's where we start and that can be a great pilot too where it can be something that's easily solved or at least one of the biggest hot big ticket items. All right. So, Mike, we have a lot more to talk about with Ontology, but I think this we have beat this down. I think we've gotten a good a good

[63:55](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3835s) Starting point here. I I don't really understand where governness is going to sit yet in ontology, what things who can add, who can't add. , my biggest I think my biggest concern here with the ontology and governance piece is what happens when something goes ary? What happens when we ask questions as to why this relationship existed? Who's going to own that? Did someone just make a decision to do that or do we come to an agreement across multiple people? I think and I also think the larger your organization becomes, the more people you're throwing at the ontology experience, the more

[64:27](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3867s) You're going to have to have alignment and conversations around what do things mean? Yeah. And like what does good enough look like? basically. So, I feel like there's a missing part of the product here that needs to be more around like data stewardship and more clearly aligning teams of people to steward the data and a way to funnel questions to them so they can quickly answer them. I I don't know know what this really looks like. This may be just more of like a process based thing that we had to establish as an organization, but there is this concept of data governance, right? We want to build these data libraries for your organization where they can go find all

[65:00](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3900s) The information that they need and work with it. But you're going to need this ability to pull back and allow people to to question why does it exist? How do we submit questions or or things here that can help them? Yeah, this data is correct. Yeah, we can verify it. Here's what we're doing to verify. Here's the proof that verifies what you're asking about these things is in fact true. So, it's going to be a new world here. I think this is going to be exciting. There's a lot of new things coming out especially and the last thing I'm going to say too is we're going to the world too especially when we're going to rely on not just the conversation but the

[65:32](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3932s) Automation side of this right where anything you didn't power automate I could I would mainly create but if we are letting an AI agent run with this off my ontology model and things go horribly all right and like again there are a lot of touch points down that road compared to a single person with power automate so a lot of things to consider here on what governance is going to be structured like. Well, that being said, let's go ahead and wrap it here. , good thoughts and topics around data governance and the ontology. I think you're going to just

[66:03](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3963s) Need to be aware of more conversations will need to be happening. Have a good structure in place. I give if you're already you don't need an ontology to start talking about data governance honestly or stewardship. I think that's a conversation that can be have right now without any ontology for that matter. So, I think it's a a good thing for organizations to unpack and put together. That being said, Tommy, where else can you find the podcast? You can find us on Apple, Spotify, or wherever you get your podcast. Make sure to subscribe and leave a rating. It helps us out a ton. Do you have a question, idea, or a topic that you want us to talk about in a future episode?

[66:34](https://www.youtube.com/watch?v=J2FY5M26Dvw&t=3994s) Head over to power.tips/mpodcast. Leave your name and a great question. And finally, join us live every Tuesday and Thursday, 7:30 a.m. Central, and join the conversation all power.tips social media channels. Thank you all for joining. We really appreciate your listenership. you could be doing a lot of other things right now, like actually getting real work done. So, go back to work, go figure out your real things, and we'll see you next time. Thank you very much.

## Thank You

Want to catch us live? Join every Tuesday and Thursday at 7:30 AM Central on YouTube and LinkedIn.

Got a question? Head to [powerbi.tips/empodcast](https://powerbi.tips/empodcast) and submit your topic ideas.

Listen on [Spotify](https://open.spotify.com/show/230fp78XmHHRXTiYICRLVv), [Apple Podcasts](https://podcasts.apple.com/us/podcast/explicit-measures-podcast-power-bi-podcast/id1534447935), or wherever you get your podcasts.
