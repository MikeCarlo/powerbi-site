---
title: "Data Agents and Semantic Models – Ep. 466"
date: "2025-10-10"
authors:
  - "Mike Carlo"
  - "Tommy Puglia"
categories:
  - "Podcast"
  - "Power BI"
tags:
  - "Explicit Measures"
  - "Podcast"
  - "Data Agents"
  - "Semantic Models"
  - "AI"
  - "Microsoft Fabric"
  - "SQLBI"
excerpt: "Mike and Tommy explore the intersection of Data Agents and semantic models—how well-built models become the foundation for AI-powered data experiences, and what best practices look like for configuring agents that actually deliver useful answers."
featuredImage: "./assets/featured.png"
---

Data Agents are only as good as the semantic models they sit on top of. Mike and Tommy make the case that your investment in semantic modeling is actually an investment in AI readiness—and walk through Microsoft's best practices for configuring Data Agents.

<iframe 
  width="100%" 
  height="415" 
  src="https://www.youtube.com/embed/jqUnzLnJg9o" 
  title="Data Agents and Semantic Models – Ep. 466"
  frameborder="0" 
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
  allowfullscreen
></iframe>

## Main Discussion: Data Agents Meet Semantic Models

### Why Semantic Models Matter for AI

SQLBI's insight resonates: semantic models give both you and Microsoft's AI a shared understanding of your data. The same measures, hierarchies, and business logic that power your reports also power Data Agents. If your model is well-built:
- AI generates better DAX queries
- Natural language questions map to the right measures
- Business definitions are consistent whether a human or agent asks

### What Is a Data Agent?

Fabric Data Agents are AI-powered interfaces that let users ask natural language questions against your data:
- Backed by semantic models (or other Fabric data sources)
- Use LLMs to translate questions into DAX queries
- Return answers in natural language with supporting data
- Configurable with instructions, examples, and guardrails

### Configuration Best Practices

Drawing from Microsoft's documentation:
- **Provide clear model descriptions** — The agent uses table/column/measure descriptions to understand your model
- **Add example questions and expected answers** — Teaches the agent the right patterns
- **Set guardrails** — Define what the agent should and shouldn't answer
- **Test iteratively** — The first configuration is never right; test with real user questions
- **Keep models clean** — Hidden columns, clear naming, documented measures all help the agent

### The Virtuous Cycle

Well-built semantic models → better agent performance → more users trusting AI answers → more investment in model quality. The teams that have been disciplined about modeling now have a head start on AI-powered analytics.

### Reference

- [Data Agent Concept — Microsoft Learn](https://learn.microsoft.com/fabric/data-science/concept-data-agent?WT.mc_id=DP-MVP-5002621)
- [How to Create a Data Agent](https://learn.microsoft.com/fabric/data-science/how-to-create-data-agent?WT.mc_id=DP-MVP-5002621)
- [Data Agent Configuration Best Practices](https://learn.microsoft.com/en-us/fabric/data-science/data-agent-configuration-best-practices?WT.mc_id=DP-MVP-5002621)

## Looking Forward

Data Agents are the first major consumer of semantic models beyond traditional BI reports. This validates years of investment in proper modeling practices and raises the stakes—a poorly modeled dataset now produces bad AI answers, not just bad reports.

## Episode Transcript

Full verbatim transcript — click any timestamp to jump to that moment:

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=0s" target="_blank">0:00</a> Heat. Heat. Good morning and welcome back to the

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=36s" target="_blank">0:36</a> Explicit Measures podcast with Tommy and Mike. Good morning everyone. It's another day, another Tuesday or Thursday or whatever day it is at this point. Work just becomes a thing, man. This is a pre-recorded episode. So, we're pre-recording this one. to this one. , for those of you who are subscribers, you can get these early episodes if you want by by checking out and becoming a member. We post them as soon as they're recorded and they go right on the YouTube channel just in case you want to look at them. , yeah, that's going to be that's going to be today's episode. Today's episode's main topic is going to be data agents and

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=70s" target="_blank">1:10</a> Semantic models. I've been doing a lot of workshops around creating a data agent, working with data agents, figuring out what data sources can be used with data agents. There's been some recent announcements around what data can be consumed inside the data agents. So that being said, we'll we'll jump in there. But before we get to our main topic, I do have a little bit of a a story, a beat from the street, as you will. I'd like to just pick your brain, Tommy, here in your previous history, whatever that may be, , working other companies, working for yourself. Where do you feel like Microsoft Dynamics sits? What what is

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=104s" target="_blank">1:44</a> That? What is that? What is that part of your ecosystem? It's pretty extensive because most organizations I worked actually every organization I worked with dynamics was one of the vital organs of how the company operated like you took you take that away and that company just falls apart and obviously then like can we do some PowerBI with it but honestly the beginning for me Mike at least they were like they were two separate like church and state type of thing. they were very separated and we wanted to integrate but like well

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=136s" target="_blank">2:16</a> No we get what we want in in dynamics because we have my account dynamics is more it's again singular base I'm looking at a single record and all the information there but then it came to that point but no for me it's it's a very aware thing part of it so why do you ask interesting the reason I ask is because as a as a smaller business right I'm a consulting firm andor software development firm and as I'm grooming a lot more of the, , feature sets and trying to get software sold. I'm growing it. I'm getting a lot more customers. I have a

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=168s" target="_blank">2:48</a> Lot more people. , I've been doing this, I've been consulting since 2019. When you're when you have a handful of customers, you can keep it on your head who's what, what projects they're on. But as your team starts growing to more people and more individuals, you need to start getting a bit more organized. And so I've been, , like looking at the landscape and saying what programs or tools that are out there and what could I use to become part of my process as I develop in my business. And so I've been doing a lot of homework around, okay, what what's dynamic sales? What does that look like? How would I

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=199s" target="_blank">3:19</a> Build it? All the things that go along with the dynamics round of things. So that's I'm I'm really going to be heavily investing and starting to install it, build process around it. , I've done a couple very large migrations for companies in the past around, , , switching different ERP systems or or migrating between things and it feels like a lot of times companies just don't adapt their process to what the program does out of the box and therefore it becomes really expensive customizations, all this other stuff. So, I'm I'm looking to say, okay, I'm going to be

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=231s" target="_blank">3:51</a> Flexible here and I will conform my process to what the program does out of the box. So that way I'm not spending a lot of extra money trying to customize or tweak things. It just works. So I'm just going to pause right there. Your thoughts? No, I for me to your point like I'm an individual consultant so I know Jim's an opportunity. I know it in my head thing or I have a task list or whatever it may be piece of paper right thing. I can manage that. But the organizations I worked with and again when I worked internally when I was a director of BI when I was a

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=263s" target="_blank">4:23</a> Data analyst it was the accountability it was the input also interesting you say too about the customization so I hated building model apps there's canvas apps which to me make more sense but model apps were so integral because of the amount of mapping and customization because well the sales team works in this method and this process so dynamics I think the reason why it's so popular like Mike I'm speaking at a conference that's dynamics based. , and you can have that, right? When is that? And that's the October dynamic summit in

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=297s" target="_blank">4:57</a> North America. But again, the point is not the speaking part, but the point is it's a whole conference really devoted around dynamics and because it's the most popular thing out there outside of like Salesforce because it adapts and it can be custom for each organization. the problem for you and I from the analytical side. I don't I'll pause there. I don't know if you wanted to take that in a different direction. No, I I just want to give you a big shout out here on like the conference and then where you will be. So that way people if they want to follow you or if they're contemplating going if you are in Dynamics or if you and

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=330s" target="_blank">5:30</a> You're speaking on some PowerBI related things at the Dynamics conference, correct? Yeah. So we're doing two things. I'm doing metric sets and then I'm doing adopting and promoting PowerBI because a lot of people are going to be introduced to it. So adopt and promoting Microsoft fabric and power behind your organization. Excellent. So that's the community summit in Orlando. That'll be this year and it's October 19th through the 23rd this year. It's at the Palms Resort, Gaylord Palms Resort and Convention Center down in Orlando, which I think I've never been there to that that facility, but I've I've been to a couple

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=362s" target="_blank">6:02</a> Other different Gaylord yeah, I guess hotel. It's like bigger than a hotel. like centers. It's massive. One of those convention hotel centers. So, I've I've heard very good things about the other locations and I've had a lot of good experiences with them. That'll be exciting. It'll be a lot of fun for you, Tommy. So, I , if you're checking it out, I'll definitely put the link in the description below. It'll be summitna.com if you want to go check it out. if I was a golfer, I would say I'd be golfing, but I'm probably not going to be golfing. So, that's true. so, I'm Yeah, I'm going

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=395s" target="_blank">6:35</a> To go back to your your point there, Tommy. Like I know every company has their own version of a CRM system. I've always felt like Dynamics has just been in the companies that I've been in, it's been more like SAP. It's been other systems. I've been working a lot more now with like recent companies around like Salesforce. That's another another system that does a lot of similar things. Customer relationship management pieces. So there's it's interesting to me to to just really dive into Dynamics because at this point up until now I knew about Dynamics. I know

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=428s" target="_blank">7:08</a> Enough about how to get the data out of Dynamics, but it was just about it was like a data source. Mhm. It was a data source for PowerBI. The tables were like how do I load them? Yeah. And I've also heard Dynamics reporting is pretty trash. Like it's just not good at all. It it does some reporting. It will give you some graphs that you need, but when you see that compared to what PowerBI can do, people immediately start clamoring for I want reports looking like PowerBI reports and getting them in from Dynamics. It's in it's really interesting you say that because this is actually one of the for me if you were to look at those

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=460s" target="_blank">7:40</a> Critical points in your career when you adapted or upgraded your own skill or experience, this was one of them because yeah, the reports were pretty interesting. However, people did not want to switch to PowerBI. They didn't want that data in PowerBI because they didn't need it because yeah, the report may have had a bad visual or bad colors or whatever it was, but the important part was we've talked about this before, they were already acting in dynamics. They were looking at their accounts. They were looking at the opportunities. So, they didn't want to go out of that

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=491s" target="_blank">8:11</a> Experience. They don't care. they there was not a lot of interest in yeah you can spice it up but I'm getting the information I need how I need it right here thing. I don't care if I can click and drill through. So it's when we talk about giving data to people it's is that big shift there too. And this is outside the fact Mike that dynamics up until we can mirror we started being able to mirror in fabric was horrendous to try to do reporting in. Every table is 170 columns and does not bode well. You should have seen the

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=523s" target="_blank">8:43</a> Old documentation. The old documentation on Microsoft for power query to connect to it. It wasn't just here are the functions in Dynamics. It was oh well make sure you add this extra parameter in the code and only do this. It was all these things to make it work. You're like Microsoft you own both these products. Make them work. Yeah. But yeah. Yeah. And I think also to be very clear the Dynamics product is a transactional system. It's a system where you go in addedit records of things and that's why there's like these really wide tables

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=555s" target="_blank">9:15</a> That are not this is this is the classic example of data is designed for what the app needs in order to do the work. It's not designed for the reporting needs on the other side which means you're going to be picking up lots of columns. You need to join lots of tables together to get to the entries that you want. It's not simp simple and seamless here. And also I Tommy I would argue as well when Dynamics gets really large a lot of times people have this expectation of well I updated the record in Dynamics why does that record not appear immediately inside PowerBI and PowerBI is not good at well at the time

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=587s" target="_blank">9:47</a> Anyways is what I'm I'm recalling a little bit here PowerBI is not the best having things like immediately funnel through and trickle through to the report side all the time because you had to like refresh a lot of tables you weren't able just to do incremental refresh refreshes on certain record and it's it takes a lot more design on the report side to have it refresh faster with only the records you care about. That's just something else I think is interesting here is this this game between the transactional system and then the operational system or the the online analytical processing system.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=622s" target="_blank">10:22</a> There's there's two worlds in what you want to think about, right? And it's funny to go down that nerdy path because like PowerBI is a columner based system. So it does very well taking an individual column treating it as a table which is the opposite of dynamics and dynamics is a row based system right recordbased system. So and it's interesting that your own dynamics keep me updated on that because I'm I'm going to be curious on two things on this path for you. I'm going to be curious on how much customization do you start doing because out of the box is fine but again

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=654s" target="_blank">10:54</a> Every business is different and then where does all the because Microsoft's biggest push initially with AI was in the power platform. Yes. So I'm interested on where that becomes integrated in your process too with with dynamics in that journey. I'll I'll keep you in tabs Tommy on this because I'm also because when I look at the documentation as I'm reading up on the program there's a lot of like AI based things but more like finding opportunities writing letters to people like there's there's a lot of things that are just yes there's document feeding things like what are your products how do you so there seem

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=686s" target="_blank">11:26</a> There's going to be a lot of things I think they're going to integrate there from the dynamics AI side of things I'll let cuz I'm I'll I'll play with it a bit more I it seems helpful but again I'm leerary cuz if anything like all the co-pilots that have been trying to Q&amp;A my results and things it's not really going to be helpful we'll it's actually take this with a great salt we'll see what happens it's actually pretty good it's like why can't we have this much AI work in power fabric so you I'm curious well speaking of AI what a segue by the way so you're

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=719s" target="_blank">11:59</a> All yeah so what are we talking about today so today we're going to talk about data agents and your semantic models so transition away from AI and dynamics. Let's move over to what does a data agent look like inside your semantic model and how does that work. So there's a number of articles that Microsoft has been producing around this one. There is a single item an actual product workload is an issue if you want to call it that that exists in the workspace called a data agent and there's some concepts of it there's how to create one but let's unpack like what does this

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=753s" target="_blank">12:33</a> Mean for organizations and how should we be thinking about what is a data agent and how does it work in relation to what we're doing in BI teams. So Tommy that's where I'm going to start here. What do you where do you want to take the conversation here? There's some fundamental concepts here when we start with the data agent and this is probably maybe our even fourth episode talking about data agents but again it's only available on an F2 or above. So this is not available on your not the free capacity, not the free capacity, not even the trial I believe. No, you can get this trial. No trial.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=785s" target="_blank">13:05</a> You have to have a dedicated fabric capacity to run it, right? And simply what a data agent is or really taking the mold of AI agents is simply allowing the conversational question and answer again chatbased. So like your messaging, not just this the Q&amp;A feature that allows an ask questions plain English that are stored in one lake and receive content rich accurate answers. Again, no, they say no technical expertise required. The conversation's there, I'm sure. But again,

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=815s" target="_blank">13:35</a> I genally agree with that. , , generally that feels about right. You're not writing code. , you are talking to it like a natural language like to set one up. I would agree. There's no code involved if you want. Right. Right. And yeah, the setup for the for the author, the creator is all going to be statement based. So you're going to be writing what you want it to tell prompting you're really doing prompt engineering and again how it works it uses parsing validating questions and it queries tables based on the data source which is very unique

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=849s" target="_blank">14:09</a> Here it's not simply taking well we're going to be write everything in Python and then generate the query that's how at cloud chatgpt everything's written in python if you want some analytical answers this is based on the data source so if I'm using SQL like a table source in SQL. It's going to write a SQL query on the back end if I'm using which I can also use not just raw tables. I can use what we'll be talking about today, semantic models. It's going to write NL2 DAX or DAX statement to generate your answer and then to generate the summary.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=883s" target="_blank">14:43</a> Okay. You said NL2 DAX language. Yeah. So, yeah. So, make sure you use the right terms cuz there's there's multiple engines that it's deciding on how to communicate. Yeah, they've developed this where there's NL2 which is their second iteration natural language to DAX, natural language to SQL, natural language to KQL which is which is another query. So those are the three main databases they talk to are SQL, KQL and semantic models, right? And of the three I would say again looking at like what Microsoft is

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=915s" target="_blank">15:15</a> Doing and how you can train models they've definitely have been spending a lot of time. This feels like there's a lot of thoughts going on here. Let me just give a couple thoughts here. Yeah. Yeah. They've been spending a lot of time on building these natural language processors to write queries that can then be used against different data sources. So it feels like the effort has been spent building these natural language translators. And when you think about the three different types we're talking about here, the one that's probably the most common is SQL. Like so SQL is very known. There's a lot of it out there.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=948s" target="_blank">15:48</a> You can train a lot on the SQL. DAX is pretty prevalent but only in the Microsoft realm. So it's very specific to like our tools, the things that we do and KQL I think also is very similar as well. It's a niche product. There's not a lot of training things that can be done on top of the KQL. So my argument would be here is like when you're when you're going to a SQL data source, I found pretty good results and the SQL that it was writing was pretty neat complex joins. It was understanding things. it was doing really well in the SQL side of things. However, the DAX and

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=982s" target="_blank">16:22</a> The KQL side, it did okay on the DAX. , think it did really good. I think they're definitely improving that because why not? Because that's the same natural language to DAX you would need to run in other parts of the tool as well. So, they have to make this better. But you can definitely tell there's not as much background knowledge or background training that's on these other two languages, right? And one we'll do the last bit of comparison here as well because a lot of people may be asking what about co-pilot isn't co-pilot a data agent? No. So these are separate entities. A fabric data agent. It is again is

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1015s" target="_blank">16:55</a> Configurable with instructions. Copilot is pretty preconfigured. It's what you get out of the box. It's like getting you open up the box with the toy. The toy works. That's all you can do. This one is your open source. You can, , update the update the motherboard and fabric data agent is standalone, but it's also crossplatform. I can use a data agent in copilot studio and allow it to work with copilot studio. Copilot studio is not just again what's in fabric. That's something that's a Microsoft product that works across all

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1047s" target="_blank">17:27</a> Of your products, all of your systems, all of your content. So those are the biggest differences with a data agent because the point that makes a data agent so impactful Mike is the instructionbased side of things that you're writing a data agent with a specific task or task. it's rather than co-pilot where is more of the Q&amp;A I may want a data agent to do something again a custom specific something and this is where the data agent can really shine and Mike you've had a lot of experience well we both had a lot of experience

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1079s" target="_blank">17:59</a> But you've actually done these these trainings already the sessions which is awesome and from from you building it I I'll start with you what have you found as did you have any oh wow moments of like hey this is actually neat in terms of the building side not necessarily the user experience side the there there is a way of like adjusting how it talks to you. So your instructions that you give it definitely do change the responses that are coming back from the large language model. So one one time I was building an agent and I wanted to be more like you

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1112s" target="_blank">18:32</a> Know fun and energetic and said make your responses more lively and energetic add puns and jokes into the responses that come out of the AI just just to be silly like just to see what it would do and it did it. , it was actually responding with like, , it would give you the answers that you needed and then it would also like add a little quip or a little bit of like a pun on top of that. So, that was fun to see the agent doing things. Those are like if you think about what Q&amp;A does, there's no ability for you to give it personality or something a bit more human side to it cuz a lot of the

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1145s" target="_blank">19:05</a> Q&amp;A just feels very straight laced. , it's just this product had this percent change at this time D. It just did a lot of readout of things. It wasn't more like someone wrote it, right? It wasn't conversational in nature. So for that regard, like the large language model did a better job on like letting it be feeling more human as you interacted with it. I think that'll get better over time. Imagine Tommy, , now I'm starting to see in other products even right when we start talking about what types of service desk things that are coming out

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1179s" target="_blank">19:39</a> Of different experiences like hey there's now agents that are going to be like able to answer your phone call when people are not there. They'll pick up a call and then they'll talk to the person on the other line. Schedule an appointment, schedule a demo, actually have someone like actually you you tell it what you want it to do and it's not like you're telling it step by step. , I feel like the when you call someone and they're you get like the the automated voice messaging, right? It's just very canned like, "Hi, what's your name?" And you say your name and you're like, "Thanks, Michael." Like when I'm pounding zero on my phone,

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1212s" target="_blank">20:12</a> Right? I same thing. I'm like, "Give me a real person." Right? I think the experience is adjusting now. And with the advent of AI agents and the ability to like in real time get voice commands going through there, it sounds much more fluid like hello, welcome. How can I help you today? Like it sounds more like a real person and the voice side of things are are much better. Even even to the point now, Tommy, people are doing like take my voice or take the leader's voice or take the person who's running the business's voice, put that voice in the agent and have the agent on behalf

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1245s" target="_blank">20:45</a> Of them talking to the customers. Hey, my name is, , Robert and I'm the owner of the business. How can I help you? Like something like that. And this is, , hey, I'm a virtual agent for Robert. How can I help you? And so you you can start making that much more interactive. So that's the part I think that is you're getting with data agents is this more conversational space around what the data is doing. Now any aha moments it did a good job making tables. It did a good job of like finding like specific questions.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1276s" target="_blank">21:16</a> It wasn't really good at like interpreting the data. So if you asked it for like where are some places where we are lacking sales like it could tell you where sales were down but it wasn't doing a good job of saying giving you reasons why the sales were down right hey I found three factors that might make sense as to why these sales were down in this certain region or on this product or whatever it was more about asking factual data back to it so it it felt a lot more like general knowledge extraction from data

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1309s" target="_blank">21:49</a> Sets is what it look like right now initially. Yeah, I think that'll get better over time, but right now there's not a lot of like advanced analytics in there. It's not it's not running like regression analysis. It's not able to like determine what other things are going on. So, it it really feels like that. And there's a lot of there's very little today. Again, I'm I'm assuming this is going to change at some point. There's very little visual support. So, you can get a table out, it'll give you some answers. That's basically as far as you can get. And maybe you can jump into like an explore feature where you explore the data and from there you can build your own

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1340s" target="_blank">22:20</a> Visuals on top of like it gets you close right where you might need to be thinking about or looking at but then it's up to you to take it from there and keep building on top of it to potentially get down to the answer or insight that you're thinking about. I'll just pause there. No, I I I have that's so much to dive into. But quick side note by the way about talking to people on the phone the those automated messages. I've never been more vulgar in my life than when I get a terrible automated messaging machine to try to get to someone. I've never been meaner to anyone in my life when it is that system where it's just

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1373s" target="_blank">22:53</a> They don't understand what you're saying. It's like, "Please say what you want." Like, "I don't know. There's 1,800 things at this insurance company I can do." And then you say one thing like, "Do you want to talk to sales?" Like, "No, I've never been more of a what you're just a mean person." Let's just put it that way. But what I'm trying to say with systems and maybe there is I maybe these agents have the ability to be able to detect sentiment or convers like so like these conversations should start off with like there should be an an innate read or measure on your voice and how

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1406s" target="_blank">23:26</a> You're talking to them cuz it should say okay this person is now happy this person's now frustrated this person is now angry it should it should be able to interpret how I'm talking to it based on the words and the tone of my voice and then from there it should be able to realize like, okay, this is not helping like whatever whatever I'm saying, , we'll, , I'm sorry for your frustration. I'll get you to an operator. Like that's there's times when we know that needs to happen and to your point, Tommy, you get stuck in these loops of like I just need to talk to someone and it won't let you.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1438s" target="_blank">23:58</a> You the words I've called literally my wife's been upstairs and she just hears get it together and she's like, who are you talking to? I'm like AI. So yes, totally. We got to get there. No, but let me actually get back because you made a very very good point here about interpreting the data and I think this is the the crux of our conversation today. So there's a few articles that we have that will be in the podcast and will be in YouTube. There's one by Marco Russo as well that talks about experience with LLMs that there's no better consumption than

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1469s" target="_blank">24:29</a> The semantic model. The problem with large language models or let's say the lack of large language models working with data is the structure of the data. Again, these things just don't work out of the box. It needs to be fed a ton of information and raw data while can support it support it needs to come with certain rules or then it's just going to be a bunch of to your point AI slop or AI data slop. And this is a very interesting point about the interpreting the data. I want I want to make two

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1501s" target="_blank">25:01</a> Notes here because we'll talk about this in the Microsoft thing and then I think overall with AI we talked about the languages right so if you if you take a large data set a large raw table a CSV feed it to chat GPT and ask it to explore give me analysis it does everything in Python so all the extracting the data creating the data frame I I actually had some really cool experiences and I'm trying to put this make a session out of this where I wanted I took the raw data and I said I want you to develop metrics. This is

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1534s" target="_blank">25:34</a> What's important to me but I want you to create your own metrics. I count this and I look at the percent of three out of five percent that's what's important. Anything above three is important. create a ton of metrics for me, , that come out of this and it did some amazing things that actually incorporated into a report that actually we developed with a client to say, hey, we're actually going to use these metrics when we look at it and it changed how what the report was, but that was all Python. So that's one note to say everything here we're talking about DAX and SQL which you

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1567s" target="_blank">26:07</a> Again a data analysis expression language but very different compared to the breath of Python. The other point, raw data compared to the semantic model. There's an argument here or there's a conversation here. I want to say there's a current ongoing discussion in our community about the best data source in the fabric world for data agents and AI in general. Yes, I have a few I have a few opinions here, but Marco Russo makes the argument along with Rob Collie who have been in the game for a long time that semantic models are the preferred data source

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1601s" target="_blank">26:41</a> Here. Great. So, so we we agree with that. So, you agree with this? I would 100% agree with that cuz well, imagine imagine so that was one of the points I was going to make here is like look, I really respect the words that come out of Marco Russo's mouth. He he understands things at a level that I'll never understand things in the semantic model level. Also, Rob Kie was one of the original Power Pivot Pro individuals and also started with like Power Query inside Excel. , so I learned a lot from Rob around the Excel side of things and Power Query and data transformations. The between the two of those, there's a lot of industry

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1634s" target="_blank">27:14</a> Knowledge there around them and I trust their opinions. Like if they're saying this is the right way to go, this is the right way to go. Like I'm going to enforce what they're communicating because this makes sense to me as well. Even let's just unpack this a little bit, right? Inside the semantic model, we have tables, columns, definitions of every column by descriptions. Also you have relationships between tables and you could even communicate to the large language model these are like the way you build your measures measures are also KPIs or aggregations that you expect to do on top of the data. So

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1668s" target="_blank">27:48</a> Already you've already spent like effort or time just by making the model and creating your measures inside the semantic model even without documentation like even without writing down where every column came from and what they mean. Just doing that building of the semantic model you've already described a lot of additional data points to users. And so you're now leveraging that knowledge twice. You're leveraging it once for the users to build their own reports or you to build your reports on top of. And the second time you're leveraging it now is for the data agent.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1700s" target="_blank">28:20</a> If you didn't have that, if you're going straight KQL and SQL, right, in those areas, you need to describe the same relationships. So when I was building data agents, I had one of the data sources that was like the SQL analytics endpoint off of a lakehouse. Great. It was nice. But in there I had in order for it to build the proper connections between the tables I had to go through and define this c this table is connected to this table. Here's the relationship. This is a one to many relationship. There's this size has the one. This side has the many. And so I

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1733s" target="_blank">28:53</a> Had to feed the model that information. That way when it was doing joins in the SQL, it understood what it was joining against. And again going back to like where does the metadata live for all these things? it lives in the semantic model and you can use other tools like Unity catalog or snowflake and now they just opened up the ability for you to like mirror those items into fabric and mirrored items will now be also a part of data agents as well which is nice cuz you get a lot more data sources. But the downside of this now is where does all that metadata come from? Where does the

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1765s" target="_blank">29:25</a> Relationships come from inside those data sources? And that's to me that that's where all that's where the the custom instructions come from. Custom instructions solve that. And you can do again when you're building data agents you can build up to five right now today as of whatever today we're recording this there are only five data sources you can make inside a data agent so you can pick five different data sources and that's it in those five data sources you can have like SQL databases you can pre-prompt those data sources and add instructions specifically to SQL but you cannot for

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1797s" target="_blank">29:57</a> The semantic model so there's even even inside each data source you can add custom instructions per data source to help further design and teach the large language model what's important in these different data sources. So, I'm I'm going to add here. I don't want to go out and write say I disagree with the statement because I don't. However, however, however, there's some considerations here that I think just need to be part of the context of this conversation because obviously Mike with you, I'm not one to vehemently disagree with Marco Russo or Rob Collie who are

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1831s" target="_blank">30:31</a> Much smarter and have way more experience than I do. But let's also remember the game that we're playing here with LLM. So, there's a there's a claim here. There's I think the the real statement here is there's no better structured data source for an LLM large language model than a PowerBI semantic model. I would just change this topic because I would or I would change that statement slightly from my experience with AI modeling is there's no better structured data source than a trained LLM for a PowerBI sim model. So here's the thing though and this is is really

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1864s" target="_blank">31:04</a> Important in this conversation because like I said I don't want to come across as no this is completely false but let's also remember too an LLM works based on certain data and in a certain way to get trained to do what it needs to do or what it's being tasked to do commonly it's what we call vectorred or really input output this is the usual inputs that you'll get this is the desired output that I get think mach think even basic machine learning ing right Mike where it's like hey a cat a picture of a cat a cat a picture of a cat a p continue

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1899s" target="_blank">31:39</a> Whatever that case is but this is also very true with prompting and in a lot of models that are created on what you want it to task to do especially with agents again an agent is not what you think chatbt it's a type of agent but an agent has specific task that is going to follow out for you right compared to more the LLM which is very broad right it will do a general a general everything but when we talk about LM I okay someone's going to ask for data provide this is the expected or desired result and that's many many rows and

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1932s" target="_blank">32:12</a> Many many columns of that input output type of structure semantic models don't have that but this is why it's really important when we talked about this because I'm not saying go out of semantic models be from a structured point of view for a user to ask queries it's I'm honestly from to your point with the metadata the already structured set of relationships. You're not going to find anything necessarily better. But that's only for something trained, right? And this is really an important distinction here when we're talking about when this conversation comes up. Even the data

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1966s" target="_blank">32:46</a> Agent themselves and this is my one problem with data agents right now and all in in the experience that I have is yes, you can customize it, but you can only customize it with a prompt, right? There's no waiting. There's no training of it. The only training is just conversational, right? It's still very user friendly and we're I don't want to say we're missing the point here, but we're still very limited on allowing the data agent to do a lot what it could do. So, I'm going to pause there because I know like I said that I don't know if

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=1997s" target="_blank">33:17</a> That's a hot take. I don't know how that's going to come across, but what's your take on that? What's the reaction you have from this? , I I I my first reaction is I remember a scene from Silicon Valley where one of the one of the Oh, he not that one, but there's other ones as well. , so this is one of the characters, I can't remember his name, Jin Jinyang, I think maybe was his name. Yes, that's okay. And he was he was building there, again, this is like

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2030s" target="_blank">33:50</a> An incubator project. They're trying to build all these like software and app things. And this gentleman had built a yeah, Tommy's got the the always blue ball that that comes from the the show, but the he's building this AI app that's like getting a lot of traction and it's basically he's building an AI app that says you feed it a picture and it's like hot dog, not hot dog. Yeah. And they're like it only identifies hot dogs. Like that's He's like, "Yeah, it's not a hot dog." So it knows not this is not a hot dog. So you just would feed it a bunch of pictures and it would just be hot dog, not hot dog. Hot dog. The first three they're like hot dog.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2062s" target="_blank">34:22</a> They're like, "Wow, this is amazing." They're like, "Feed something else, not hot dog." They're like, "Oh, you mean it's just hot dog, not dog." He's like, "Yes." That's exactly. So, , that's that's what I feel like some of these initial a like when you're talking like the initial, , versions of AI, that's what it that's what it feels like a little bit. So, , it's it's definitely evolved more than that now. Like, it's definitely better than those things. And the other thing I'm I'm very optimistic or or positive about is the speed in which this AI is changing. Like how good it's

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2095s" target="_blank">34:55</a> Becoming over time. So, , what we're at right now today, I would imagine in a month or two from now, it's going to be drastically different and it'll have a lot other features or new improvements to it that we can then use and leverage and it'll be u much more usable in in the future. So, so that's something that I think is just in general. that's going to be changing so fast. Where I think I get hung up the most, Tommy, is I don't know what instructions or what are good instructions to give to it. So, that's where I'm it could probably do a lot better if I

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2128s" target="_blank">35:28</a> Gave it better instructions, but I don't even know where to start with what are good instructions. M so it almost feels like you need to have Microsoft provide you like here are some good examples of starting instructions you may want to consider and then you start from there or even have the AI build itself to some degree like hey I'm going to point at this semantic model the AI almost needs to have like a different so this is where multiple large language models working together make more sense and let me unpack this for a bit here for a

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2159s" target="_blank">35:59</a> Moment Tommy while I bear with me here while I un unwind the idea Right. The model, the AI can be used to generate its own models, but it could be a different AI. There's different kinds of AIs out in the world. There's some that are deep thinking. There are some that are some that are act agent things. I'm doing something. I'm making something happen. We have this thing called MCPs now which now lets you communicate directly to an agent, a large language model and that can then use APIs and calls and do different things and get get its own data that can then return results to the the large

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2191s" target="_blank">36:31</a> Language model to help it think about things. I I feel like the idea here is the the model that you use to build the agent is possibly different than the model that's actually used when you give it out to your customers. But it's going to help that first creator build the right instructions and say here's some things that we we would like to recommend to you. You've put a semantic model in here. I don't see a lot of descriptions in here. Do you want me to go create some descriptions for things? Yes. Here's the descriptions I think I'm going to apply to the semantic model.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2223s" target="_blank">37:03</a> And then it basically would list out all the descriptions of things and you can go in and modify them and say yes now this is good apply them back to the model where does this live inside the world of timle like how how does that does that help us does it get us any more ability to build better things with the agents so I feel like there's going to be like a a chat GPT5 or like a claude sonnet for that's going to be like helping you build the model and then when they run it they're just going to run like an open AI I generalized model with really good instructions. Right? So

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2255s" target="_blank">37:35</a> To me, this is where I think me personally is where it's a bit weak right now. There's not enough of the instruction side of things to help you build good instructions to make it really effective. And this is such an important pike part, Mike, because we're we cannot miss the fact semantic model or not with data agents, especially data agents is what we're doing is a skill and let's recognize it for what it is. prompt the prompting the instructions. This is no different than learning DAX and it should be treated that way. these

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2288s" target="_blank">38:08</a> Things do not work if you just add some general questions. And I've said this before on the podcast, Mike prompt. The next great coding language is English. And this is why. Okay, so this is a huge part of this is if you want to start using data agents effectively, you need to get better at prompt engineering, context engineering, the ability to prompt an instructions. You're not going to get away with just creating a data agent. And to your point, Mike, this is something that I'm finding lacking with the data agent. There's only two paragraphs in the Microsoft

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2320s" target="_blank">38:40</a> Documentation about yes, doing prompting and the querying here. And all it says is, , you you when you provide the AI with sample queries and question pairs, which I already just talked about is that initial data source of training it, , again, what I wanted to question, what I want to query, it references examples as future questions, matching them to relevant examples. PowerBI semantic models do not support adding sample query questions at this time. H so but for supported ones such as lakehouse and warehouse again still raw you can I know there's

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2352s" target="_blank">39:12</a> Schema to lakehouse but that's not supported here so semantic models are not supported here which is a huge disadvantage for us to I think use semantic models effectively the structure I'm going to say this the structure of the semantic model yeah I want to comment on that one I think you're I think you're right to some degree Tommy I think there's like a portion of this that's like if you can't write custom queries against the semantic model but I also would argue Am I going to write better DAXs than an AI will? I don't really I don't really know. , custom queries, we're talking like you're

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2385s" target="_blank">39:45</a> Running DAX against the model. So, I'd almost argue like yes, like it makes sense that it's not supported right now because but the other the other point here too is I'm building this agent. There come there needs to be a large amount of domain knowledge that comes with writing building these agents. like you have to know what people are going to ask of the agent. And I think a lot of these things are I don't know what people are going to ask yet. And so I feel like there's a missing feedback loop here of okay, we're going to build this agent. We're going to let it build something on top of a semantic model. Where's where's

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2418s" target="_blank">40:18</a> The funnel back to me, the developer of the agent, to understand what kinds of questions are people asking? Are those kinds of questions changing over time? Did is there topics that are coming that are very apparent inside these things, right? When is Tommy swearing at the AI agent when it gives him an answer that he doesn't like? Like what's the again back to this like which questions were responded to with frustration? What's the sentiment of this conversation as it happens over time? Those are the things, right? It's almost like I need like Google Analytics on top of the

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2451s" target="_blank">40:51</a> Conversations that are happening to the agent. And this can open up a whole bunch of other things, Tommy. like this could be like, , PII data. Where does the security go? Who can see these questions? You're going to maybe asking questions that are like very like detailed to like , , specific related things. , you could have a model that's talking about commissions and you're having people chat to the commissions model about what they're doing and how their sales are looking, right? That's very secret data and you don't want that just going out to anyone. Even the creator potentially might not even see that stuff. So there there's a lot of implications here of like how do you

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2484s" target="_blank">41:24</a> Navigate that road to give the creator of the agent the right amount of information so they can keep improving it and making it better. And this is where I think to your point Tommy going back to your your statement here around semantic models and can't have custom queries. I think there's a a large that that topic opens up to a bigger area of how do people use it, right? What are they doing in it? And I don't know if I could technically answer that based on the information that's given me to me today. The way data agents are rolled out.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2515s" target="_blank">41:55</a> And I I want to make a quick note here. There is a few other documents around configuring a data agent that's around prompting. So I want to make sure I'm giving the do and I'm not short shortsighting what's available. So there's a there is one that's called best practices for for configuring your data. Yeah, this is a lot more in-depth like dos and don't do things but again still high level. It's still top level but the your evaluation side why isn't this why isn't this document pushed into like okay I get it. Mhm. This is what agents do, right? Take this document,

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2548s" target="_blank">42:28</a> Pre-prompt the agent with this document and say, "Here's the best practices for building the agent." And there's an agent now to build the agent, right? And so it now has this documentation in front of it, and it reads your things and says, "Evaluate. Hey, I see you added these things in here based on our best recommendations. We recommend you change the word slightly here. I've rewritten it for you to to be better." Right? That's what we want. , I don't know. It's like it's like going back to like when I learned SQL inside access databases. Like it gave me like a UI that I could just, , stumble around in. And eventually I

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2582s" target="_blank">43:02</a> Started figuring out, oh, this is how a join looks. Oh, this is how you select things from a table. Oh, this is so the graphical nature of it made it easier for me to understand what was happening. In the same way, that's what should be happening here as well in the agents is it should be this. You're just going to throw some stuff at the wall. the agent will read it and then help you learn the better way to because eventually we'll all get better at prompting. Like Tommy, this is going to be our new world. Yeah. Our new world will be talking with agents, , people are going to they're not going to I honestly think it's going to have a slower adoption for this to be a skill on my resume or on people's resumes. It's not like again

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2615s" target="_blank">43:35</a> For me personally personally for me Mike this is something the last two years since the concept of chat GPT has been more widely available that and I'm I don't want to gloat but like is this is something I put a lot of time in or is it something that's been important in terms of like I've seen this as an important skill set so take that as you want. Okay. So doesn't mean I'm not saying I'm an expert but this is something that a lot of time. Yeah. But you've but Tommy you also picked this , how long have you been learning AI? , we've been talking in agents things with you for at

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2647s" target="_blank">44:07</a> Least a year. At least a year you've been playing with it heavily. And the important part from the experience is the prompting side is this prompt engineering or context engineering side. And I get it. Yeah. I'm saying you started a year ago. The prompting you were doing a year ago is way different than what you prompt today. Oh, yeah. Well, because the So, this is Mike. I have one of those wouldn't be nice type of things. Yeah. Yes. here here if Microsoft if you're listening give me model choice okay this is what I want this is what I want and then this will help you Microsoft okay help me help you okay this is what we we

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2680s" target="_blank">44:40</a> Should have mic is I choose a data agent but I can choose from various models and Microsoft will find what people which models they like the most maybe I want the I want the general one maybe I want the taskbased model however you want to put it but let me at least choose to your point Mike rather than giving me a blank slate which is like on the very base of the model where like feeding the AI and AI well give me a few options there on more task based ones more general ones see what people use and then focus your agent around

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2712s" target="_blank">45:12</a> That because there are different types of models it's not all these things there are different ways that these are anyways Microsoft if you're listening call me we'll talk about that so but I think to your point though Tommy like the thing I'm trying to the point I'm trying to make here is the way you prompted a year ago when you were just trying to figure this out is way different than what you're prompting now today. Also, what you were prompting in the beginning stages, the models have changed so much in a year that you're they're now more intelligent. You can set a different things. You've both the model and you have grown together to a place where

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2746s" target="_blank">45:46</a> It's like you're you're you are more in sync with like what it does and how to get the the results you expect or better results that come out. where I'm going after this. And the idea here is there's a lot of people that are now just starting to figure out data agents for the first time. So, we're we're stepping into the world here like, okay, they they have they don't have a year of knowledge of prompting things. A lot of people are just starting now to interact with them. And so my point is, how could I take Tommy's one year of prompting knowledge and distill it down to

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2778s" target="_blank">46:18</a> Something where I could in a couple months or a couple weeks beat up someone who's new to get them to the same level of prompting that you would be using, Tommy. So, like I think this is going to I think what we're going to see here is because you started earlier than everyone else, you're going to have better knowledge, but now that the models have also gotten better and and more capable and we're and we know, right? So, , Tommy, the promp the prompts you use to get the results is so important. It's pivotal to like making it really descriptive and allowing add a lot of details.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2811s" target="_blank">46:51</a> That's why now we're starting to see like when you ask a prompt like when you say a prompt make this thing. It's now what what is happening now is I think the AI agents are getting smarter and it won't just do it. It will now ask I you said this one simple thing make me a semantic model from this database and it says I think you said here's what a semantic model is. Here's the here's how I'm interpreting your question based on what you said. I've I've looked up the best practices for it. Here's a star

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2843s" target="_blank">47:23</a> Schema. Here's the tables. Like, so what what the agent is doing, it's like thinking on your question first, coming back to you with a very quick response that says, "I think you want this. Is that what you want? Do you need me to refine the requirements?" And then you're saying, you're adjusting the requirements and saying, "Yes, I want that or no, that wasn't exactly what I wanted. Change it slightly and then go do the work." It's that stuff that we never saw before. It was literally like and then you just keep it up slightly until you got it right. Now the

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2876s" target="_blank">47:56</a> Agents are thinking more on it and it's giving it's they're getting better at asking you clarifying questions to make sure they get to the right answer. So it's not wasting a bunch of time on delivering a result you didn't need. Does that make sense? Mike, this is this is a great point. Honestly, that's one of the best u techniques too when it comes to prompting is your first prompt's not going to be great. where one of the best here I'll one of the tidbits the best prompt you can say at the end of any prompt that you do is ask me any questions to get clarity and it's scary how it's like actually speaking I know you want this but since you asked

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2909s" target="_blank">48:29</a> Me to ask you to get clarity it will give you these questions for you to answer and then it'll give you the outpat it's amazing what that difference will do but to your point and is yeah there's all these concepts we got to learn here and also bring that back to the semantic model. Mike, this is how I see where data agents and semantic models are. Regardless of the prompting techniques that you do, if you were to choose, you look at your lakeouses, look at your warehouse, look at the mirror databases, look at semantic models. The best highway system for a for data agents to work is the semantic model. It has the

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2943s" target="_blank">49:03</a> Best structure. It has the best navigation. It has the best grid to get most efficiently. However, what we're missing still is the subway system, the transit and the cars on that subway. And that's the examples in the input output. If you look at the limitations right now with data agent semantic models for me, and I hate saying this is still a deal breakaker because it's not going to achieve the desired results consistently. And I I'm emphasizing the operative word here is consistently because it can deliver the right result.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=2976s" target="_blank">49:36</a> But one thing I found working with AI agents and working with these models is if you're right, if the agent gives you the right output three out of six times, I'm not using it. And most people are not either, right? They expect these things to work when they use it, not half the time. And to me, so I need a better success rate, but that becomes with the things that are still limited right now with semantic models. Again, that being said, it's not the semantic models fault, right? So this is very much with the data agents limitations

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3009s" target="_blank">50:09</a> Working with them. The best structure for AI is going to be a semantic model by far and away because of the analytical metadata because of the structure because of the quality of that data which is so important. The data agents going to work the most effectively there. We are still at a point in this date and age and on se in September October of the year 2025 where that is still a limitation here but that doesn't mean that I can feed not feed it

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3043s" target="_blank">50:43</a> Thing. Mike, I've worked with some local models and I I fed a semantic model of XML point and it's incredible how well it can interpret that information compared to a raw CSV because it's not and the reason why Mike is it's not taking the raw data and then cleaning it up itself. It's already having that clean thing with the clear instructions. But again right now when we will look at that relationship with a data agent and a semantic model there are limitations on the data agent side not the semantic model side that are still making this a hard road to cross.

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3076s" target="_blank">51:16</a> Mhm. Yeah. Again, I would agree with you, Tommy, that there's I still would argue that whether you're going to use a semantic model or not, right? If you're going to go to a data source that doesn't have the semantic model, you still need that language that describes how the data is related, what data is there. So, either you're going to use the semantic model, which already has this like let's call it like proven business logic, right? It's proven because those relationships between the tables are already producing visuals and reports, right? It it it

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3108s" target="_blank">51:48</a> Incorporates enough business logic to say these tables are related in these ways. We've aggregate this way. This is we've defined the business logic of like this is how we communicate our data. That's why I think the semantic model makes so much sense here is because it's it's taking that already existing business knowledge that's already prepackaged up. Now, can we do more things? Yes, we can. Can we can we use agents to help us document more of that? Yes, we can. how that all improves the performance of the agent. And so this is again

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3141s" target="_blank">52:21</a> I guess it's like a data engineering technique or data science technique where he says bad data in bad it out one of the so if you put junk in you're going to get junk out. If you put junk, if you if you clean up the input information, better model, better data, more joins, like if you give it more, if you do more work on the front side of things, the output becomes exponentially better on the other side. And this is one of the data science techniques, right? If you're trying to train a a model or do some AI prediction

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3173s" target="_blank">52:53</a> Thing, you could tweak the algorithm all day long and you could keep tuning performance here or there, but usually the largest gains you're going to get from that, if you study the data science world, it's cleaner data coming in, right? Clean the data coming in, making sure that it's better, it's it's more in line with what's really representative of what you want to predict. And the more you clean the data and the more you get better data into the system, the better the results will be on the other side. And it's and it's not just like a a little bit of a bump like when you're tuning the model, you're getting minor

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3205s" target="_blank">53:25</a> Improvements. It's like drastic improvements, large amounts of improvements. So this is the same to me. This feels like the same thing, right? It's going to be another area where we're going to say clean the data, make it better, produce better things around the data pieces, and that's going to continue to improve how good the agent is able to respond a thousand%. And this is be near my closing thought, but Mike, you you had a Nintendo 64, right? I I did. Okay. So, the best way to think about this too, why the semantic model is the most efficient, not just what what you said is again a all these large language

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3238s" target="_blank">53:58</a> Models are what you call token based. It takes, , it only has so much context that it can provide then understand what it needs to do and then actually do it. And think about Zelda 64. Do you remember that? I do remember that one. I love data. And but you remember if you rented the game, you were like, "Okay, I hope this is one with a good saved because all those Nintendo 64s was based data on it." That's funny. I don't remember I don't remember renting them. I bought bought the game, but I never

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3269s" target="_blank">54:29</a> I never rented a game that had good save data on there because I I was That's interesting though because then you're hoping it had like good Yeah. You're like, I hope I'm far. I'm hoping I'm adult Link. Exactly. Right. But my buddy actually he would he on the good ones he would put a black had a marker and he would he would put a dash on it. So before he actually rented it for the weekend not to waste his weekend it's like okay this is one of the good ones. Wow. Raw data is the child link. Okay. because it has you have to build it up already once you get started with it because again any raw data include and

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3303s" target="_blank">55:03</a> Even lake houses too Mike it already you're now tasking the data agent to go through the raw data and util and consume and use a lot of its tokens just to get to a point where semantic model already is semantic model already has the horse it already has all the arrows and all the features and power so it can do so much more so that's this whole argument or this conversation that's again in the community right now. The reason why the semantic model is going to be that source is because all the groundwork is already in a sense condensed. The model still needs to

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3338s" target="_blank">55:38</a> Understand it but it's condensed in terms of the rules, restrictions, etc. which is not something that has to do on its own with the raw model. And also what we can do with a semantic model, hide the columns, weight things, put the descriptions to your mic, there's nothing that comes close. in terms of what is actually capable and then also I can't wait to see where the limitations are finally overcome by Microsoft with data agents with and semantic model relationship what a data agents

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3371s" target="_blank">56:11</a> Capabilities are going to be because it's going to be extensive again so and I think that's going to be my closing thought here is right now to go back to the initial question here is do we agree with The statement is the better. There's no better structured data source for a large language model than a semantic model. You better believe it at this point in time. If you're listening, make sure you look at the limitations with that in the data agent to understand what's going to be capable or not. And also my last part to what you I think we've really emphasized here,

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3404s" target="_blank">56:44</a> Learn prompt engineering, learn context engineering, get good at it because that is such an you're not going to succeed without that. I would agree with that one 100% Tommy and I would I also echo it's like this is this is a I I really feel like this is like an a refle reflection an inflection moment. This this is a this is a moment in time where things are substantially changing for the good for the better. But this is a this is an area where it's still new. It's still every couple months I feel like I'm I'm behind again because it's

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3435s" target="_blank">57:15</a> It's so it's moving so fast. The agents are getting so much better. they're changing how they're working you now and now it feels like the new trend is it's not just going to one agent it's a matter of like orchestrating multiple agents together to do certain things so what does that look like for me when I look at the agent side fabric maybe my final thought here is I think it's an area to stay in tune with I think organizations are going to like it one thing I will caution here as well is agents are pretty intense when it comes to CU usage so in the demos that

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3469s" target="_blank">57:49</a> I've done in the times that I've I've done it. I'm doing I'm the one person just building the agent and I was on an F2 or an F4 and I saw a good amount of usage in the interactive side. So data agents when you prompt them when you talk to them use a fair amount of consumption units CUS. It it is good for organizations because it will be able to search through things. It'll be able to like give context to what people are asking questions around. It definitely feels like a better medium. But I will also argue like yes it does this very well

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3503s" target="_blank">58:23</a> But it it just be careful with it. Right. Consider Yeah. Right. That to me that is where you just need to be considerate of the usage of that. And so what I would say right now especially since this is newer out if you're on exploring this or figuring this out I would recommend getting a smaller dedicated capacity to do your testing on this. I would not put this on the same capacity that is your production. I would I would do some testing on the side seeing how agents work because I think that will give you some context to how much how much

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3535s" target="_blank">58:55</a> Prompting can be used in order to leverage these agents. So that's just my initial opinion. I think this is going to be in general when I stand back and look at what's going on inside data agents and what's happening here. I'm very optimistic. I think this is going to be super useful. I think this is a way bigger improvement over just Q&amp;A stuff on top of visuals. I wish there was a bit more visual based pieces to this where I could ask a couple questions, get a table of data, tell it to visualize this in a chart and then go from there to like a report or

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3567s" target="_blank">59:27</a> To me a lot of this is what now? What's next? Right? Can the agent go to the semantic model, grab a couple tables, pull a query together, and then pull it to analyze Excel? Can we do that? Right now, it doesn't appear to be happening. Right? So there's a couple like there's the there's a story of like talk to the agent, get to a certain point with the information and the data and then what there's a there's a what action is being done. Do we push that into a report? Do we push that out to Excel? Do we push it to an export? What

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3599s" target="_blank">59:59</a> Is the right next step that goes on from there? And how do you save that information? Once you get to an answer, once you get to some analysis, where does that go? So that to me I think that's the next evolution of where data agents are going to be. Yes, it's going to help you dig through your data and let you see it, but then there's the story of what next? Where do we go from here? So all that being said, I think we've burned through a perfectly good hour here of your time. I hope you enjoy our conversation around data agents. Tommy and I have been actively exploring them and using them and doing demonstrations around data agents. I

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3632s" target="_blank">60:32</a> Think they're very interesting, very powerful. but there's still a lot more to be developed inside them to make it super more effective for your organization. So I'm I'm optimistic. I think this is one of the better features that they've released that I feel like I'm I'm optimistic that it's going to go well. Anyways, that being said, if you like the podcast, if you like this episode, please, if you wouldn't mind, consider subscribing. members of this video or members of our channel get all these videos as they are produced. So this is a pre-recorded episode. you'll get it as

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3665s" target="_blank">61:05</a> Soon as you have it, as soon as we record. So, I want to put up on the YouTube channel. It'll be there right away. , we're also going to be doing more YouTube instructional pieces as well. Tommy and myself are going to do a bit more of this as well. So, you probably also become a member because that will get you direct access to our chat in more learning sessions that we're going to be doing in the future here as well. That being said, Tommy, where else can you find the podcast? You can find us on Apple, Spotify, or wherever you get your podcast. Make sure to subscribe and leave a rating. It helps us out a ton. And to Mike's point, share with a friend. We we really do this for free. Do you have a question

<a href="https://www.youtube.com/watch?v=jqUnzLnJg9o&t=3696s" target="_blank">61:36</a> Idea or topic that you want us to talk about? Maybe you've had experience with data agents or you want to learn more about it. Head over to powerbi.tipsodcast. Leave your name and a great question. And finally, join us live every Tuesday and Thursday, 7:30 a.m. Central, and join the conversation on all of PowerB.tips social media channels. Awesome. Thank you all so much, and we'll see you next time. Heat. Heat.

## Thank You

Want to catch us live? Join every Tuesday and Thursday at 7:30 AM Central on YouTube and LinkedIn.

Got a question? Head to [powerbi.tips/empodcast](https://powerbi.tips/empodcast) and submit your topic ideas.

Listen on [Spotify](https://open.spotify.com/show/230fp78XmHHRXTiYICRLVv), [Apple Podcasts](https://podcasts.apple.com/us/podcast/explicit-measures-podcast-power-bi-podcast/id1534447935), or wherever you get your podcasts.
